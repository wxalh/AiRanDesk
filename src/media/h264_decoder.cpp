#include "h264_decoder.h"
#include "logger_manager.h"
#include <QDebug>
#include <QMap>
#include <QMutex>

// ç¡¬ä»¶è®¾å¤‡ä¸Šä¸‹æ–‡ç®¡ç†å™¨ - å•ä¾‹æ¨¡å¼ï¼Œé¿å…é‡å¤åˆ›å»ºç¡¬ä»¶ä¸Šä¸‹æ–‡
class HardwareContextManager
{
public:
    static HardwareContextManager& instance() {
        static HardwareContextManager instance;
        return instance;
    }
    
    AVBufferRef* getDeviceContext(const QString& hwAccel) {
        QMutexLocker locker(&m_mutex);
        
        if (m_contexts.contains(hwAccel)) {
            AVBufferRef* ctx = m_contexts[hwAccel];
            if (ctx) {
                // å¢åŠ å¼•ç”¨è®¡æ•°å¹¶è¿”å›
                return av_buffer_ref(ctx);
            } else {
                // æ¸…ç†æ— æ•ˆçš„ä¸Šä¸‹æ–‡
                m_contexts.remove(hwAccel);
            }
        }
        
        // åˆ›å»ºæ–°çš„ç¡¬ä»¶è®¾å¤‡ä¸Šä¸‹æ–‡
        AVHWDeviceType deviceType = av_hwdevice_find_type_by_name(hwAccel.toUtf8().data());
        if (deviceType == AV_HWDEVICE_TYPE_NONE) {
            LOG_ERROR("Hardware device type not found: {}", hwAccel);
            return nullptr;
        }
        
        AVBufferRef* newCtx = nullptr;
        int ret = av_hwdevice_ctx_create(&newCtx, deviceType, nullptr, nullptr, 0);
        if (ret < 0) {
            // å¯¹äºQSVï¼Œå°è¯•ä½¿ç”¨"auto"å‚æ•°
            if (hwAccel == "qsv") {
                ret = av_hwdevice_ctx_create(&newCtx, deviceType, "auto", nullptr, 0);
            }
            
            if (ret < 0) {
                char errbuf[AV_ERROR_MAX_STRING_SIZE];
                av_strerror(ret, errbuf, sizeof(errbuf));
                LOG_WARN("Failed to create shared hardware device context {}: {}", hwAccel, errbuf);
                return nullptr;
            }
        }
        
        // ç¼“å­˜ä¸Šä¸‹æ–‡
        m_contexts[hwAccel] = newCtx;
        LOG_DEBUG("Created shared hardware device context for: {}", hwAccel);
        
        // è¿”å›æ–°çš„å¼•ç”¨
        return av_buffer_ref(newCtx);
    }
    
    void cleanup() {
        QMutexLocker locker(&m_mutex);
        for (auto it = m_contexts.begin(); it != m_contexts.end(); ++it) {
            if (it.value()) {
                av_buffer_unref(&it.value());
            }
        }
        m_contexts.clear();
        LOG_DEBUG("Cleared all shared hardware device contexts");
    }
    
private:
    QMap<QString, AVBufferRef*> m_contexts;
    QMutex m_mutex;
    
    HardwareContextManager() = default;
    ~HardwareContextManager() {
        cleanup();
    }
};

H264Decoder::H264Decoder(QObject *parent)
    : QObject(parent)
    , m_codecContext(nullptr)
    , m_codec(nullptr)
    , m_frame(nullptr)
    , m_swFrame(nullptr)
    , m_convertFrame(nullptr)
    , m_packet(nullptr)
    , m_swsContext(nullptr)
    , m_hwDeviceCtx(nullptr)
    , m_hwPixelFormat(AV_PIX_FMT_NONE)
    , m_initialized(false)
    , m_waitingForKeyFrame(true)
    , m_consecutiveErrors(0)
    , m_lastGoodFrameTimestamp(0)
{
}

H264Decoder::~H264Decoder()
{
    cleanup();
}

QStringList H264Decoder::getAvailableHWAccels()
{
    QStringList hwAccels;

    // æ£€æŸ¥ç¡¬ä»¶è®¾å¤‡ç±»å‹æ”¯æŒï¼Œè€Œä¸æ˜¯ç‰¹å®šçš„è§£ç å™¨
    const char* deviceTypes[] = {
        "qsv",        // Intel Quick Sync (ä¼˜å…ˆæ£€æµ‹)
        "cuda",       // NVIDIA CUDA
        "dxva2",      // Windows DirectX
        "d3d11va",    // Windows Direct3D 11
        "videotoolbox", // macOS
        "v4l2m2m",      // Linux V4L2
        "omx",          // OpenMAX
        "rkmpp",       // Rockchip MPP
        "mpp",         // MPP
        "mppenc",     // MPP Encoder
        nullptr
    };
    
    for (int i = 0; deviceTypes[i]; ++i) {
        AVHWDeviceType type = av_hwdevice_find_type_by_name(deviceTypes[i]);
        if (type != AV_HWDEVICE_TYPE_NONE) {
            // å°è¯•åˆ›å»ºè®¾å¤‡ä¸Šä¸‹æ–‡æ¥éªŒè¯æ”¯æŒ
            AVBufferRef* testCtx = nullptr;
            int ret = av_hwdevice_ctx_create(&testCtx, type, nullptr, nullptr, 0);
            if (ret >= 0) {
                LOG_INFO("Found supported hardware device: {}", deviceTypes[i]);
                hwAccels << deviceTypes[i];
                av_buffer_unref(&testCtx);
            } else {
                // å¯¹äºQSVï¼Œå°è¯•"auto"å‚æ•°
                if (strcmp(deviceTypes[i], "qsv") == 0) {
                    ret = av_hwdevice_ctx_create(&testCtx, type, "auto", nullptr, 0);
                    if (ret >= 0) {
                        LOG_INFO("Found supported hardware device: {} (with auto)", deviceTypes[i]);
                        hwAccels << deviceTypes[i];
                        av_buffer_unref(&testCtx);
                    } else {
                        char errbuf[AV_ERROR_MAX_STRING_SIZE];
                        av_strerror(ret, errbuf, sizeof(errbuf));
                        LOG_DEBUG("Hardware device not supported: {} - {}", deviceTypes[i], errbuf);
                    }
                } else {
                    char errbuf[AV_ERROR_MAX_STRING_SIZE];
                    av_strerror(ret, errbuf, sizeof(errbuf));
                    LOG_DEBUG("Hardware device not supported: {} - {}", deviceTypes[i], errbuf);
                }
            }
        } else {
            LOG_DEBUG("Hardware device type not found: {}", QString::fromUtf8(deviceTypes[i]));
        }
    }

    return hwAccels;
}

bool H264Decoder::initialize(const QString& hwAccel)
{
    QMutexLocker locker(&m_mutex);
    
    if (m_initialized) {
        cleanup();
    }
    
    // æ™ºèƒ½è‡ªé€‚åº”ç¡¬ä»¶åŠ é€Ÿé€‰æ‹©ç­–ç•¥
    bool success = false;
    if (!hwAccel.isEmpty()) {
        LOG_INFO("Attempting to initialize H264 decoder with {} acceleration", hwAccel);
        success = initializeCodec(hwAccel);
    } else {
        QStringList hwAccels = getAvailableHWAccels();
        LOG_INFO("Available hardware decoders: {}", hwAccels.join(", "));
        if (!hwAccels.isEmpty()) {
            // å¤šå±‚æ¬¡è‡ªé€‚åº”ç­–ç•¥ï¼šæŒ‰ç¡¬ä»¶ç±»å‹å’Œå…¼å®¹æ€§æ’åº
            QStringList adaptiveOrder;
            
            // ç¬¬ä¸€ä¼˜å…ˆçº§ï¼šä¸“ç”¨ç¡¬ä»¶åŠ é€Ÿå™¨ï¼ˆæœ€é«˜æ•ˆï¼‰
            if (hwAccels.contains("cuda")) adaptiveOrder << "cuda";          // NVIDIAä¸“ç”¨
            
            // ç¬¬äºŒä¼˜å…ˆçº§ï¼šé€šç”¨DirectXç¡¬ä»¶åŠ é€Ÿï¼ˆå…¼å®¹æ€§å¥½ï¼‰
            if (hwAccels.contains("d3d11va")) adaptiveOrder << "d3d11va";    // ç°ä»£DirectX
            if (hwAccels.contains("dxva2")) adaptiveOrder << "dxva2";        // ä¼ ç»ŸDirectX
            
            // ç¬¬ä¸‰ä¼˜å…ˆçº§ï¼šå‚å•†ç‰¹å®šåŠ é€Ÿå™¨ï¼ˆå¯èƒ½æœ‰å…¼å®¹æ€§é—®é¢˜ï¼‰
            if (hwAccels.contains("qsv")) adaptiveOrder << "qsv";            // Intel QSV
            
            LOG_INFO("Adaptive hardware acceleration order: {}", adaptiveOrder.join(" -> "));
            
            // é€ä¸€å°è¯•ç¡¬ä»¶åŠ é€Ÿå™¨
            for (const QString& hwType : adaptiveOrder) {
                LOG_INFO("Attempting hardware acceleration: {}", hwType);
                if (initializeCodec(hwType)) {
                    LOG_INFO("âœ“ Successfully initialized H264 decoder with {} hardware acceleration", hwType);
                    success = true;
                    break;
                } else {
                    LOG_WARN("âœ— Failed to initialize {} hardware acceleration, trying next", hwType);
                }
            }
        }
    }
    
    // è‡ªé€‚åº”å›é€€ç­–ç•¥ï¼šå¦‚æœæ‰€æœ‰ç¡¬ä»¶åŠ é€Ÿéƒ½å¤±è´¥ï¼Œä½¿ç”¨é«˜æ•ˆçš„è½¯ä»¶è§£ç 
    if (!success) {
        LOG_WARN("All hardware acceleration failed, falling back to optimized software decoding");
        success = initializeCodec(QString());
    }
    
    if (success) {
        m_initialized = true;
        QString accelType = m_hwAccelName.isEmpty() ? "software" : m_hwAccelName;
        LOG_INFO("ğŸ¯ H264 decoder successfully initialized with {} acceleration", accelType);
        
        // æ€§èƒ½ä¼˜åŒ–æç¤º
        if (m_hwAccelName.isEmpty()) {
            LOG_INFO("ğŸ’¡ Using optimized software decoding - consider upgrading GPU drivers for hardware acceleration");
        } else {
            LOG_INFO("ğŸš€ Hardware acceleration active - optimal performance enabled");
        }
    } else {
        LOG_ERROR("âŒ Failed to initialize H264 decoder with any method");
        cleanup();
    }
    
    return success;
}

bool H264Decoder::initializeCodec(const QString& hwAccel)
{
    // æŸ¥æ‰¾è§£ç å™¨ - å¯¹äºç¡¬ä»¶è§£ç ï¼Œä½¿ç”¨æ ‡å‡†h264è§£ç å™¨è€Œä¸æ˜¯ç‰¹å®šçš„ç¡¬ä»¶è§£ç å™¨
    QString codecName = "h264";  // å§‹ç»ˆä½¿ç”¨æ ‡å‡†h264è§£ç å™¨
    m_codec = avcodec_find_decoder_by_name(codecName.toUtf8().data());
    
    if (!m_codec) {
        LOG_ERROR("Codec {} not found", codecName);
        return false;
    }
    
    LOG_DEBUG("Found codec: {}", codecName);
    
    // åˆ›å»ºè§£ç å™¨ä¸Šä¸‹æ–‡
    m_codecContext = avcodec_alloc_context3(m_codec);
    if (!m_codecContext) {
        LOG_ERROR("Could not allocate video codec context");
        return false;
    }
    
    // æ™ºèƒ½ç¡¬ä»¶åŠ é€Ÿåˆå§‹åŒ–
    bool hardwareInitialized = false;
    if (!hwAccel.isEmpty()) {
        LOG_DEBUG("Setting hardware decoding parameters for: {}", hwAccel);
        if (initializeHardwareAccel(hwAccel)) {
            // è®¾ç½®get_formatå›è°ƒå‡½æ•°ï¼Œè¿™æ˜¯ç¡¬ä»¶è§£ç çš„å…³é”®
            m_codecContext->get_format = get_hw_format;
            m_codecContext->opaque = this;  // ä¼ é€’thisæŒ‡é’ˆç»™å›è°ƒå‡½æ•°
            hardwareInitialized = true;
            LOG_DEBUG("Hardware acceleration setup completed for: {}", hwAccel);
        } else {
            LOG_WARN("Hardware acceleration setup failed for: {}", hwAccel);
        }
    }
    
    // æ‰“å¼€è§£ç å™¨ï¼ˆç¡¬ä»¶æˆ–è½¯ä»¶ï¼‰
    int ret = avcodec_open2(m_codecContext, m_codec, nullptr);
    if (ret < 0) {
        char errbuf[AV_ERROR_MAX_STRING_SIZE];
        av_strerror(ret, errbuf, sizeof(errbuf));
        
        if (hardwareInitialized) {
            LOG_WARN("Hardware decoder failed to open ({}): {}", hwAccel, errbuf);
            LOG_INFO("Attempting graceful fallback to software decoding");
            
            // æ¸…ç†ç¡¬ä»¶èµ„æº
            avcodec_free_context(&m_codecContext);
            if (m_hwDeviceCtx) {
                av_buffer_unref(&m_hwDeviceCtx);
                m_hwDeviceCtx = nullptr;
            }
            m_hwPixelFormat = AV_PIX_FMT_NONE;
            
            // é‡æ–°åˆ›å»ºè½¯ä»¶è§£ç å™¨ä¸Šä¸‹æ–‡
            m_codecContext = avcodec_alloc_context3(m_codec);
            if (!m_codecContext) {
                LOG_ERROR("Could not allocate software video codec context");
                return false;
            }
            
            ret = avcodec_open2(m_codecContext, m_codec, nullptr);
            if (ret < 0) {
                av_strerror(ret, errbuf, sizeof(errbuf));
                LOG_ERROR("Software decoder also failed: {}", errbuf);
                return false;
            }
            
            LOG_INFO("âœ“ Graceful fallback to software decoding successful");
            m_hwAccelName.clear();  // æ¸…é™¤ç¡¬ä»¶åŠ é€Ÿæ ‡è¯†
        } else {
            LOG_ERROR("Software decoder failed to open: {}", errbuf);
            return false;
        }
    } else {
        if (hardwareInitialized) {
            LOG_DEBUG("âœ“ Hardware decoder opened successfully: {}", hwAccel);
        } else {
            LOG_DEBUG("âœ“ Software decoder opened successfully");
        }
    }
    
    // åˆ†é…å¸§
    m_frame = av_frame_alloc();
    if (!m_frame) {
        LOG_ERROR("Could not allocate video frame");
        return false;
    }
    
    // å¦‚æœä½¿ç”¨ç¡¬ä»¶åŠ é€Ÿï¼Œåˆ†é…è½¯ä»¶å¸§ç”¨äºè½¬æ¢
    if (!hwAccel.isEmpty()) {
        m_swFrame = av_frame_alloc();
        if (!m_swFrame) {
            LOG_ERROR("Could not allocate software frame");
            return false;
        }
    }
    
    // åˆ†é…æ•°æ®åŒ…
    m_packet = av_packet_alloc();
    if (!m_packet) {
        LOG_ERROR("Could not allocate packet");
        return false;
    }
    
    m_hwAccelName = hwAccel;
    LOG_INFO("Decoder initialization completed for: {}", hwAccel.isEmpty() ? "software" : hwAccel);
    return true;
}

bool H264Decoder::initializeHardwareAccel(const QString& hwAccel)
{
    // æ ¹æ®ä¸åŒçš„ç¡¬ä»¶åŠ é€Ÿå™¨è®¾ç½®åƒç´ æ ¼å¼
    if (hwAccel == "cuda") {
        m_hwPixelFormat = AV_PIX_FMT_CUDA;
    } else if (hwAccel == "qsv") {
        // QSVé€šè¿‡DirectXæ¥å£å·¥ä½œï¼Œä¼˜å…ˆä½¿ç”¨D3D11æ ¼å¼
        // æ³¨æ„ï¼šè¿™é‡Œè®¾ç½®ä¸€ä¸ªæœŸæœ›çš„æ ¼å¼ï¼Œå®é™…æ ¼å¼ç”±get_hw_formatå›è°ƒå†³å®š
        m_hwPixelFormat = AV_PIX_FMT_D3D11;
        LOG_INFO("QSV will use DirectX interfaces (D3D11/DXVA2) for hardware acceleration");
    } else if (hwAccel == "dxva2") {
        m_hwPixelFormat = AV_PIX_FMT_DXVA2_VLD;
    } else if (hwAccel == "d3d11va") {
        m_hwPixelFormat = AV_PIX_FMT_D3D11;
    } else if (hwAccel == "videotoolbox") {
        m_hwPixelFormat = AV_PIX_FMT_VIDEOTOOLBOX;
    } else if (hwAccel == "rkmpp") {
        // Rockchip MPP é€šå¸¸é€šè¿‡ DRM PRIME è¾“å‡ºç¡¬ä»¶å¸§
        // å®é™…å¯ç”¨æ ¼å¼ç”± get_hw_format ä» pix_fmts å†³ç­–ã€‚
        m_hwPixelFormat = AV_PIX_FMT_DRM_PRIME;
        LOG_INFO("RKMPP hardware acceleration expected format: {}", av_get_pix_fmt_name(m_hwPixelFormat));
    } else {
        LOG_WARN("Unknown hardware accelerator: {}", hwAccel);
        return false;
    }

    LOG_INFO("Setting initial hardware pixel format: {} for {}", av_get_pix_fmt_name(m_hwPixelFormat), hwAccel);

    // ä½¿ç”¨å…±äº«çš„ç¡¬ä»¶è®¾å¤‡ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    LOG_INFO("Getting shared hardware device context for: {}", hwAccel);
    m_hwDeviceCtx = HardwareContextManager::instance().getDeviceContext(hwAccel);

    if (!m_hwDeviceCtx) {
        LOG_ERROR("Failed to get hardware device context for: {}", hwAccel);
        return false;
    }

    LOG_INFO("Successfully obtained hardware device context for {}", hwAccel);

    // å°†ç¡¬ä»¶è®¾å¤‡ä¸Šä¸‹æ–‡åˆ†é…ç»™è§£ç å™¨ä¸Šä¸‹æ–‡
    m_codecContext->hw_device_ctx = av_buffer_ref(m_hwDeviceCtx);
    LOG_INFO("Successfully assigned hardware device context to decoder");
    return true;
}

QImage H264Decoder::decodeFrame(const rtc::binary& h264Data)
{
    QMutexLocker locker(&m_mutex);
    
    if (!m_initialized) {
        LOG_ERROR("Decoder not initialized");
        return QImage();
    }
    
    if (h264Data.empty()) {
        return QImage();
    }
    
    // è®¾ç½®æ•°æ®åŒ…
    m_packet->data = const_cast<uint8_t*>(reinterpret_cast<const uint8_t*>(h264Data.data()));
    m_packet->size = static_cast<int>(h264Data.size());
    
    // å‘é€æ•°æ®åŒ…åˆ°è§£ç å™¨
    int ret = avcodec_send_packet(m_codecContext, m_packet);
    if (ret < 0) {
        char errbuf[AV_ERROR_MAX_STRING_SIZE];
        av_strerror(ret, errbuf, sizeof(errbuf));
        LOG_ERROR("Error sending packet to decoder: {}", errbuf);
        return QImage();
    }
    
    // æ¥æ”¶è§£ç åçš„å¸§
    ret = avcodec_receive_frame(m_codecContext, m_frame);
    if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF) {
        return QImage(); // éœ€è¦æ›´å¤šæ•°æ®æˆ–ç»“æŸ
    } else if (ret < 0) {
        char errbuf[AV_ERROR_MAX_STRING_SIZE];
        av_strerror(ret, errbuf, sizeof(errbuf));
        LOG_ERROR("Error receiving frame from decoder: {}", errbuf);
        return QImage();
    }
    
    // å¦‚æœæ˜¯ç¡¬ä»¶å¸§ï¼Œéœ€è¦è½¬æ¢åˆ°ç³»ç»Ÿå†…å­˜
    AVFrame* frameToConvert = m_frame;
    AVPixelFormat frameFormat = static_cast<AVPixelFormat>(m_frame->format);

    // æ£€æŸ¥æ˜¯å¦æ˜¯ç¡¬ä»¶æ ¼å¼ï¼ˆä»»ä½•éè½¯ä»¶æ ¼å¼éƒ½éœ€è¦è½¬æ¢ï¼‰
    bool isHardwareFrame = (frameFormat != AV_PIX_FMT_YUV420P &&
                           frameFormat != AV_PIX_FMT_YUV422P &&
                           frameFormat != AV_PIX_FMT_YUV444P &&
                           frameFormat != AV_PIX_FMT_NV12 &&
                           frameFormat != AV_PIX_FMT_NV21) ||
                          (!m_hwAccelName.isEmpty() && frameFormat != AV_PIX_FMT_YUV420P);

    if (isHardwareFrame && m_swFrame && !m_hwAccelName.isEmpty()) {
        // RKMPP/DRM_PRIME åœ¨ä¸åŒ FFmpeg ç‰ˆæœ¬ä¸Šå¯¹ç›´æ¥ transfer åˆ° NV12 çš„æ”¯æŒä¸ä¸€è‡´ã€‚
        // è¿™é‡Œä¼˜å…ˆé€‰æ‹©æ›´é€šç”¨çš„ YUV420P ä½œä¸ºè½¯å¸§ç›®æ ‡ï¼Œåç»­å†ç»Ÿä¸€è½¬ NV12/RGBã€‚
        AVPixelFormat transferTarget = AV_PIX_FMT_NV12;
        if (frameFormat == AV_PIX_FMT_DRM_PRIME || m_hwAccelName == "rkmpp") {
            transferTarget = AV_PIX_FMT_YUV420P;
        }

        LOG_DEBUG("Detected hardware frame format: {}, transferring to software {}", 
                  av_get_pix_fmt_name(frameFormat), av_get_pix_fmt_name(transferTarget));

        m_swFrame->format = transferTarget;
        m_swFrame->width = m_frame->width;
        m_swFrame->height = m_frame->height;

        // ä¸ºè½¯ä»¶å¸§åˆ†é…ç¼“å†²åŒº - é‡ç”¨ç°æœ‰ç¼“å†²åŒºæˆ–åˆ†é…æ–°çš„
        if (m_swFrame->buf[0]) {
            int required_size = av_image_get_buffer_size(transferTarget,
                                                       m_swFrame->width, m_swFrame->height, 32);
            if (m_swFrame->buf[0]->size >= required_size) {
                av_frame_unref(m_swFrame);
                m_swFrame->format = transferTarget;
                m_swFrame->width = m_frame->width;
                m_swFrame->height = m_frame->height;
                LOG_DEBUG("Reusing existing software frame buffer");
            } else {
                av_frame_unref(m_swFrame);
                m_swFrame->format = transferTarget;
                m_swFrame->width = m_frame->width;
                m_swFrame->height = m_frame->height;
                int ret2 = av_frame_get_buffer(m_swFrame, 32);
                if (ret2 < 0) {
                    char errbuf[AV_ERROR_MAX_STRING_SIZE];
                    av_strerror(ret2, errbuf, sizeof(errbuf));
                    LOG_ERROR("Error allocating software frame buffer: {}", errbuf);
                    return QImage();
                }
                LOG_DEBUG("Allocated new software frame buffer");
            }
        } else {
            int ret2 = av_frame_get_buffer(m_swFrame, 32);
            if (ret2 < 0) {
                char errbuf[AV_ERROR_MAX_STRING_SIZE];
                av_strerror(ret2, errbuf, sizeof(errbuf));
                LOG_ERROR("Error allocating software frame buffer: {}", errbuf);
                return QImage();
            }
            LOG_DEBUG("Allocated initial software frame buffer");
        }

        int ret2 = av_hwframe_transfer_data(m_swFrame, m_frame, 0);
        if (ret2 < 0) {
            char errbuf[AV_ERROR_MAX_STRING_SIZE];
            av_strerror(ret2, errbuf, sizeof(errbuf));
            LOG_ERROR("Error transferring frame data from hardware: {}", errbuf);
            return QImage();
        }

        LOG_DEBUG("Successfully transferred hardware frame to software {} format", av_get_pix_fmt_name(transferTarget));
        frameToConvert = m_swFrame;
    } else {
        LOG_DEBUG("Using software frame format: {}", av_get_pix_fmt_name(frameFormat));
        // å¦‚æœæ˜¯è½¯ä»¶è§£ç ä½†ä¸æ˜¯NV12æ ¼å¼ï¼Œéœ€è¦è½¬æ¢ä¸ºNV12ç»Ÿä¸€å¤„ç†
        if (frameFormat != AV_PIX_FMT_NV12) {
            frameToConvert = convertToNV12(m_frame);
            if (!frameToConvert) {
                LOG_WARN("Failed to convert software frame to NV12, using original format");
                frameToConvert = m_frame;
            }
        } else {
            frameToConvert = m_frame;
        }
    }
    
    // è½¬æ¢ä¸ºQImage
    QImage result = avframeToQImage(frameToConvert);
    
    // æ¸…ç†æ•°æ®åŒ…å¼•ç”¨
    av_packet_unref(m_packet);
    
    // æ¸…ç†å¸§æ•°æ®å¼•ç”¨ï¼ˆä¿ç•™å¸§å¯¹è±¡ç”¨äºé‡ç”¨ï¼‰
    av_frame_unref(m_frame);
    if (m_swFrame && frameToConvert == m_swFrame) {
        // å¦‚æœä½¿ç”¨äº†è½¯ä»¶å¸§ï¼Œä¹Ÿæ¸…ç†å…¶å¼•ç”¨
        av_frame_unref(m_swFrame);
    }
    
    // æ¸…ç†è½¬æ¢äº§ç”Ÿçš„ä¸´æ—¶å¸§
    if (frameToConvert != m_frame && frameToConvert != m_swFrame) {
        av_frame_free(&frameToConvert);
    }
    
    return result;
}

AVFrame* H264Decoder::convertToNV12(AVFrame* inputFrame)
{
    if (!inputFrame) {
        return nullptr;
    }
    
    AVPixelFormat inputFormat = static_cast<AVPixelFormat>(inputFrame->format);
    if (inputFormat == AV_PIX_FMT_NV12) {
        // å·²ç»æ˜¯NV12æ ¼å¼ï¼Œç›´æ¥è¿”å›
        return inputFrame;
    }
    
    // åˆ›å»ºè½¬æ¢å¸§
    AVFrame* nv12Frame = av_frame_alloc();
    if (!nv12Frame) {
        LOG_ERROR("Failed to allocate NV12 conversion frame");
        return nullptr;
    }
    
    nv12Frame->format = AV_PIX_FMT_NV12;
    nv12Frame->width = inputFrame->width;
    nv12Frame->height = inputFrame->height;
    
    int ret = av_frame_get_buffer(nv12Frame, 32);
    if (ret < 0) {
        char errbuf[AV_ERROR_MAX_STRING_SIZE];
        av_strerror(ret, errbuf, sizeof(errbuf));
        LOG_ERROR("Failed to allocate NV12 frame buffer: {}", errbuf);
        av_frame_free(&nv12Frame);
        return nullptr;
    }
    
    // åˆ›å»ºè½¬æ¢ä¸Šä¸‹æ–‡
    struct SwsContext* swsCtx = sws_getContext(
        inputFrame->width, inputFrame->height, inputFormat,
        nv12Frame->width, nv12Frame->height, AV_PIX_FMT_NV12,
        SWS_BILINEAR, nullptr, nullptr, nullptr
    );
    
    if (!swsCtx) {
        LOG_ERROR("Failed to create sws context for NV12 conversion");
        av_frame_free(&nv12Frame);
        return nullptr;
    }
    
    // æ‰§è¡Œè½¬æ¢
    int scaledHeight = sws_scale(swsCtx,
                                inputFrame->data, inputFrame->linesize, 0, inputFrame->height,
                                nv12Frame->data, nv12Frame->linesize);
    
    sws_freeContext(swsCtx);
    
    if (scaledHeight != inputFrame->height) {
        LOG_ERROR("Failed to convert frame to NV12: expected {} lines, got {}", inputFrame->height, scaledHeight);
        av_frame_free(&nv12Frame);
        return nullptr;
    }
    
    LOG_DEBUG("Successfully converted {} frame to NV12", av_get_pix_fmt_name(inputFormat));
    return nv12Frame;
}

QImage H264Decoder::avframeToQImage(AVFrame* frame)
{
    if (!frame) {
        return QImage();
    }
    
    int width = frame->width;
    int height = frame->height;
    AVPixelFormat inputFormat = static_cast<AVPixelFormat>(frame->format);
    
    // å¯¹äºæŸäº›ç¡¬ä»¶æ ¼å¼ï¼Œå…ˆè½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
    AVFrame* frameToUse = frame;
    
    // æ£€æŸ¥æ˜¯å¦éœ€è¦ä¸­é—´è½¬æ¢ï¼ˆæŸäº›FFmpegç‰ˆæœ¬å¯¹NV12->RGB24çš„sws_scaleæ”¯æŒæœ‰é—®é¢˜ï¼‰
    if (inputFormat == AV_PIX_FMT_NV12) {
        // ä½¿ç”¨æˆå‘˜å˜é‡é‡ç”¨è½¬æ¢å¸§
        if (!m_convertFrame) {
            m_convertFrame = av_frame_alloc();
            if (!m_convertFrame) {
                LOG_ERROR("Failed to allocate convert frame");
                return QImage();
            }
        } else {
            av_frame_unref(m_convertFrame); // æ¸…ç†ä¹‹å‰çš„æ•°æ®
        }
        
        m_convertFrame->format = AV_PIX_FMT_YUV420P;
        m_convertFrame->width = width;
        m_convertFrame->height = height;
        
        // åªåœ¨éœ€è¦æ—¶é‡æ–°åˆ†é…ç¼“å†²åŒº
        if (!m_convertFrame->buf[0] || 
            m_convertFrame->buf[0]->size < av_image_get_buffer_size(AV_PIX_FMT_YUV420P, width, height, 32)) {
            int ret = av_frame_get_buffer(m_convertFrame, 32);
            if (ret < 0) {
                LOG_ERROR("Failed to allocate convert frame buffer");
                return QImage();
            }
        }
        
        // åˆ›å»ºä¸´æ—¶swsä¸Šä¸‹æ–‡è¿›è¡ŒNV12->YUV420Pè½¬æ¢
        struct SwsContext* tempSwsCtx = sws_getContext(
            width, height, AV_PIX_FMT_NV12,
            width, height, AV_PIX_FMT_YUV420P,
            SWS_BILINEAR, nullptr, nullptr, nullptr
        );
        
        if (tempSwsCtx) {
            sws_scale(tempSwsCtx,
                      frame->data, frame->linesize, 0, height,
                      m_convertFrame->data, m_convertFrame->linesize);
            sws_freeContext(tempSwsCtx);
            frameToUse = m_convertFrame;
            inputFormat = AV_PIX_FMT_YUV420P;
        } else {
            LOG_WARN("Failed to create NV12->YUV420P converter, using direct conversion");
            frameToUse = frame;
            inputFormat = static_cast<AVPixelFormat>(frame->format);
        }
    }
    
    // åˆ›å»ºæˆ–æ›´æ–°å›¾åƒæ ¼å¼è½¬æ¢å™¨
    if (!m_swsContext || 
        sws_isSupportedInput(inputFormat) <= 0) {
        
        if (m_swsContext) {
            sws_freeContext(m_swsContext);
        }
        
        m_swsContext = sws_getContext(
            width, height, inputFormat,
            width, height, AV_PIX_FMT_RGB24,
            SWS_BILINEAR, nullptr, nullptr, nullptr
        );
        
        if (!m_swsContext) {
            LOG_ERROR("Could not initialize sws context for format {}", av_get_pix_fmt_name(inputFormat));
            return QImage();
        }
    }
    
    // åˆ›å»ºQImage
    QImage image(width, height, QImage::Format_RGB888);
    
    // è®¾ç½®ç›®æ ‡æ•°æ®æŒ‡é’ˆ
    uint8_t* dstData[1] = { image.bits() };
    int dstLinesize[1] = { static_cast<int>(image.bytesPerLine()) };
    
    // è½¬æ¢YUVåˆ°RGB
    int result = sws_scale(m_swsContext,
              frameToUse->data, frameToUse->linesize, 0, height,
              dstData, dstLinesize);
    
    if (result != height) {
        LOG_ERROR("sws_scale failed: expected {} lines, got {}", height, result);
        return QImage();
    }
    
    return image;
}

void H264Decoder::cleanup()
{
    // é˜²æ­¢ä¸ decodeFrame æˆ–å…¶ä»–çº¿ç¨‹å¹¶å‘æ¸…ç†ï¼Œä½¿ç”¨äº’æ–¥é”ä¿è¯çº¿ç¨‹å®‰å…¨
    QMutexLocker locker(&m_mutex);

    // æ ‡è®°ä¸ºæœªåˆå§‹åŒ–ï¼Œé˜»æ­¢æ–°çš„è§£ç è¯·æ±‚è¿›å…¥
    m_initialized = false;

    if (m_packet) {
        av_packet_free(&m_packet);
        m_packet = nullptr;
    }

    if (m_frame) {
        av_frame_free(&m_frame);
        m_frame = nullptr;
    }

    if (m_swFrame) {
        av_frame_free(&m_swFrame);
        m_swFrame = nullptr;
    }

    if (m_convertFrame) {
        av_frame_free(&m_convertFrame);
        m_convertFrame = nullptr;
    }

    if (m_swsContext) {
        sws_freeContext(m_swsContext);
        m_swsContext = nullptr;
    }

    if (m_codecContext) {
        avcodec_free_context(&m_codecContext);
        m_codecContext = nullptr;
    }

    // é‡Šæ”¾ç¡¬ä»¶è®¾å¤‡ä¸Šä¸‹æ–‡çš„å¼•ç”¨ï¼ˆå…±äº«ç®¡ç†å™¨ä¼šå¤„ç†å®é™…çš„é‡Šæ”¾ï¼‰
    if (m_hwDeviceCtx) {
        av_buffer_unref(&m_hwDeviceCtx);
        m_hwDeviceCtx = nullptr;
    }

    m_codec = nullptr;
    m_hwPixelFormat = AV_PIX_FMT_NONE;
    m_hwAccelName.clear();
    m_initialized = false;

    LOG_DEBUG("H264Decoder cleanup completed");
}

// ç¡¬ä»¶è§£ç çš„å…³é”®å›è°ƒå‡½æ•° - æ ¹æ®FFmpegå®˜æ–¹ç¤ºä¾‹
enum AVPixelFormat H264Decoder::get_hw_format(AVCodecContext *ctx, const enum AVPixelFormat *pix_fmts)
{
    H264Decoder* decoder = static_cast<H264Decoder*>(ctx->opaque);
    if (!decoder) {
        LOG_ERROR("Decoder instance is null in get_hw_format callback");
        return AV_PIX_FMT_NONE;
    }
    
    const enum AVPixelFormat *p;
    
    LOG_DEBUG("get_hw_format called, target format: {}", av_get_pix_fmt_name(decoder->m_hwPixelFormat));
    LOG_DEBUG("Available pixel formats:");
    for (p = pix_fmts; *p != AV_PIX_FMT_NONE; p++) {
        LOG_DEBUG("  - {}", av_get_pix_fmt_name(*p));
    }
    
    // é¦–å…ˆæ£€æŸ¥æ˜¯å¦æœ‰æˆ‘ä»¬æœŸæœ›çš„ç¡¬ä»¶æ ¼å¼
    for (p = pix_fmts; *p != AV_PIX_FMT_NONE; p++) {
        if (*p == decoder->m_hwPixelFormat) {
            LOG_INFO("Selected exact hardware pixel format: {}", av_get_pix_fmt_name(*p));
            return *p;
        }
    }
    
    // å¦‚æœæ²¡æœ‰æ‰¾åˆ°å®Œå…¨åŒ¹é…çš„æ ¼å¼ï¼Œæ ¹æ®ç¡¬ä»¶åŠ é€Ÿå™¨ç±»å‹é€‰æ‹©æœ€ä½³æ ¼å¼
    LOG_DEBUG("Target format {} not found, trying best available format for {}", 
             av_get_pix_fmt_name(decoder->m_hwPixelFormat), decoder->m_hwAccelName);
    
    for (p = pix_fmts; *p != AV_PIX_FMT_NONE; p++) {
        // å¯¹äºRKMPPï¼Œä¼˜å…ˆé€‰æ‹© DRM_PRIME
        if (decoder->m_hwAccelName == "rkmpp") {
            if (*p == AV_PIX_FMT_DRM_PRIME) {
                LOG_INFO("Selected DRM_PRIME format for Rockchip RKMPP hardware acceleration");
                decoder->m_hwPixelFormat = *p;
                return *p;
            }
        }

        // å¯¹äºQSVï¼Œä¼˜å…ˆé€‰æ‹©D3D11/DXVA2æ ¼å¼ï¼ˆè¿™æ˜¯QSVå®é™…ä½¿ç”¨çš„æ ¼å¼ï¼‰
        if (decoder->m_hwAccelName == "qsv") {
            if (*p == AV_PIX_FMT_D3D11) {
                LOG_INFO("Selected D3D11 format for Intel QSV hardware acceleration");
                // æ›´æ–°è§£ç å™¨çš„ç¡¬ä»¶åƒç´ æ ¼å¼ï¼Œç¡®ä¿åç»­å¤„ç†æ­£ç¡®
                decoder->m_hwPixelFormat = *p;
                return *p;
            }
            if (*p == AV_PIX_FMT_DXVA2_VLD) {
                LOG_INFO("Selected DXVA2 format for Intel QSV hardware acceleration");
                decoder->m_hwPixelFormat = *p;
                return *p;
            }
            if (*p == AV_PIX_FMT_D3D11VA_VLD) {
                LOG_INFO("Selected D3D11VA format for Intel QSV hardware acceleration");
                decoder->m_hwPixelFormat = *p;
                return *p;
            }
            // QSVä¹Ÿå¯èƒ½ç›´æ¥æ”¯æŒQSVæ ¼å¼
            if (*p == AV_PIX_FMT_QSV) {
                LOG_INFO("Selected native QSV format for Intel QSV hardware acceleration");
                decoder->m_hwPixelFormat = *p;
                return *p;
            }
        }
        // å¯¹äºCUDA
        else if (decoder->m_hwAccelName == "cuda") {
            if (*p == AV_PIX_FMT_CUDA) {
                LOG_INFO("Selected CUDA format for hardware acceleration");
                decoder->m_hwPixelFormat = *p;
                return *p;
            }
        }
        // å¯¹äºDXVA2
        else if (decoder->m_hwAccelName == "dxva2") {
            if (*p == AV_PIX_FMT_DXVA2_VLD) {
                LOG_INFO("Selected DXVA2 format for hardware acceleration");
                decoder->m_hwPixelFormat = *p;
                return *p;
            }
        }
        // å¯¹äºD3D11VA
        else if (decoder->m_hwAccelName == "d3d11va") {
            if (*p == AV_PIX_FMT_D3D11VA_VLD || *p == AV_PIX_FMT_D3D11) {
                LOG_INFO("Selected D3D11VA format for hardware acceleration: {}", av_get_pix_fmt_name(*p));
                decoder->m_hwPixelFormat = *p;
                return *p;
            }
        }
    }
    
    // æ¬¡ä¼˜é€‰æ‹©ï¼šä»»ä½•DirectXæ ¼å¼ï¼ˆç”¨äºIntelé›†æˆæ˜¾å¡ï¼‰
    for (p = pix_fmts; *p != AV_PIX_FMT_NONE; p++) {
        if (*p == AV_PIX_FMT_D3D11 || *p == AV_PIX_FMT_DXVA2_VLD || *p == AV_PIX_FMT_D3D11VA_VLD) {
            LOG_INFO("Selected fallback DirectX format for hardware acceleration: {}", av_get_pix_fmt_name(*p));
            return *p;
        }
    }
    
    // æœ€åé€‰æ‹©ï¼šä»»ä½•ç¡¬ä»¶æ ¼å¼
    for (p = pix_fmts; *p != AV_PIX_FMT_NONE; p++) {
        if (*p == AV_PIX_FMT_CUDA 
            #ifdef _WIN32
            || *p == AV_PIX_FMT_D3D12 || *p == AV_PIX_FMT_D3D11 
            || *p == AV_PIX_FMT_DXVA2_VLD || *p == AV_PIX_FMT_D3D11VA_VLD
            #endif
        ) {
            LOG_INFO("Selected any available hardware format: {}", av_get_pix_fmt_name(*p));
            return *p;
        }
    }
    
    // å¦‚æœåªæœ‰è½¯ä»¶æ ¼å¼å¯ç”¨ï¼Œè­¦å‘Šå¹¶é€‰æ‹©YUV420P
    for (p = pix_fmts; *p != AV_PIX_FMT_NONE; p++) {
        if (*p == AV_PIX_FMT_YUV420P) {
            LOG_WARN("No hardware pixel formats available, falling back to SOFTWARE decoding with yuv420p");
            LOG_WARN("Hardware acceleration for {} will not be used", decoder->m_hwAccelName);
            return *p;
        }
    }
    
    LOG_ERROR("No suitable pixel format found");
    return AV_PIX_FMT_NONE;
}

bool H264Decoder::validateHardwareDecoding()
{
    // å¦‚æœæ²¡æœ‰ç¡¬ä»¶åŠ é€Ÿå™¨åç§°ï¼Œè¯´æ˜æ˜¯è½¯ä»¶è§£ç ï¼Œæ— éœ€éªŒè¯
    if (m_hwAccelName.isEmpty()) {
        return true;
    }
    
    LOG_DEBUG("Validating hardware decoding for: {}", m_hwAccelName);
    
    // æ£€æŸ¥è§£ç å™¨ä¸Šä¸‹æ–‡æ˜¯å¦æ­£ç¡®è®¾ç½®
    if (!m_codecContext) {
        LOG_ERROR("Codec context is null during validation");
        return false;
    }
    
    // æ£€æŸ¥æ˜¯å¦è®¾ç½®äº†get_formatå›è°ƒå‡½æ•°ï¼ˆç¡¬ä»¶è§£ç çš„å…³é”®ï¼‰
    if (!m_codecContext->get_format) {
        LOG_WARN("get_format callback not set - hardware decoding may not work");
        return false;
    }
    
    // æ£€æŸ¥ç¡¬ä»¶è®¾å¤‡ä¸Šä¸‹æ–‡æ˜¯å¦å­˜åœ¨
    if (!m_hwDeviceCtx) {
        LOG_WARN("Hardware device context is null - hardware acceleration not active");
        return false;
    }
    
    // æ£€æŸ¥ç¡¬ä»¶åƒç´ æ ¼å¼æ˜¯å¦è®¾ç½®
    if (m_hwPixelFormat == AV_PIX_FMT_NONE) {
        LOG_WARN("Hardware pixel format not set - may fall back to software");
        return false;
    }
    
    LOG_DEBUG("âœ“ Hardware decoding validation passed for: {}", m_hwAccelName);
    return true;
}
