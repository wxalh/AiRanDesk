#include "h264_encoder.h"
#include "logger_manager.h"
#include <QDebug>
#include <cstdio>

// ç¡¬ä»¶è®¾å¤‡ä¸Šä¸‹æ–‡ç®¡ç†å™¨ - å•ä¾‹æ¨¡å¼ï¼Œé¿å…é‡å¤åˆ›å»ºç¡¬ä»¶ä¸Šä¸‹æ–‡
class HardwareContextManager
{
public:
    static HardwareContextManager &instance()
    {
        static HardwareContextManager instance;
        return instance;
    }

    AVBufferRef *getDeviceContext(const QString &hwAccel)
    {
        QMutexLocker locker(&m_mutex);

        if (m_contexts.contains(hwAccel))
        {
            AVBufferRef *ctx = m_contexts[hwAccel];
            if (ctx)
            {
                return av_buffer_ref(ctx);
            }
            else
            {
                m_contexts.remove(hwAccel);
            }
        }

        AVHWDeviceType deviceType = av_hwdevice_find_type_by_name(hwAccel.toUtf8().data());
        if (deviceType == AV_HWDEVICE_TYPE_NONE)
        {
            LOG_ERROR("Hardware device type not found: {}", hwAccel);
            return nullptr;
        }

        AVBufferRef *newCtx = nullptr;
        int ret = av_hwdevice_ctx_create(&newCtx, deviceType, nullptr, nullptr, 0);
        if (ret < 0)
        {
            if (hwAccel == "qsv")
            {
                ret = av_hwdevice_ctx_create(&newCtx, deviceType, "auto", nullptr, 0);
            }

            if (ret < 0)
            {
                char errbuf[AV_ERROR_MAX_STRING_SIZE];
                av_strerror(ret, errbuf, sizeof(errbuf));
                LOG_WARN("Failed to create shared hardware device context {}: {}", hwAccel, errbuf);
                return nullptr;
            }
        }

        m_contexts[hwAccel] = newCtx;
        LOG_DEBUG("Created shared hardware device context for: {}", hwAccel);
        return av_buffer_ref(newCtx);
    }

private:
    QMap<QString, AVBufferRef *> m_contexts;
    QMutex m_mutex;
};

H264Encoder::H264Encoder(QObject *parent)
    : QObject(parent), m_codecContext(nullptr), m_codec(nullptr), m_frame(nullptr)
    , m_hwFrame(nullptr), m_packet(nullptr), m_swsContext(nullptr), m_hwDeviceCtx(nullptr)
    , m_width(0), m_height(0), m_fps(30), m_bitrate(2000000), m_frameCount(0)
    , m_hwPixelFormat(AV_PIX_FMT_NONE), m_initialized(false), m_forceKeyFrame(false)
{
    m_h264Bsf = nullptr;
}

H264Encoder::~H264Encoder()
{
    cleanup();
}

QStringList H264Encoder::getAvailableHWAccels()
{
    QStringList hwAccels;

    // æ£€æŸ¥å¸¸è§çš„ç¡¬ä»¶åŠ é€Ÿå™¨ï¼ŒæŒ‰ä¼˜å…ˆçº§æ’åº
    const char *accelNames[] = {
        "nvidia",       // NVIDIA CUDA
        "cuda",       // NVIDIA CUDA
        "nvenc",        // NVIDIA
        "amf",          // AMD
        "vaapi",       // Intel VAAPI
        "qsv",          // Intel Quick Sync (ä¼˜å…ˆæ£€æµ‹)
        "vulkan",     // Vulkan
        // "mf",     // Microsoft Media Foundation
        "videotoolbox", // macOS
        "v4l2m2m",      // Linux V4L2
        "omx",          // OpenMAX
        "rkmpp",       // Rockchip MPP
        "mpp",         // MPP
        "mppenc",     // MPP Encoder
        nullptr};

    for (int i = 0; accelNames[i]; ++i)
    {
        QString codecName = QString("h264_%1").arg(accelNames[i]);
        const AVCodec *codec = avcodec_find_encoder_by_name(codecName.toUtf8().data());
        if (codec)
        {
            // å®é™…æµ‹è¯•ç¼–ç å™¨æ˜¯å¦å¯ç”¨ï¼ˆåˆ›å»ºä¸Šä¸‹æ–‡å¹¶å°è¯•æ‰“å¼€ï¼‰
            AVCodecContext *testContext = avcodec_alloc_context3(codec);
            if (testContext)
            {
                // è®¾ç½®æœ€å°æµ‹è¯•å‚æ•°
                testContext->width = 640;
                testContext->height = 480;
                testContext->time_base = AVRational{1, 30};
                testContext->framerate = AVRational{30, 1};
                testContext->pix_fmt = AV_PIX_FMT_NV12;
                
                // å¯¹äºQSVï¼Œè°ƒæ•´åˆ†è¾¨ç‡ä¸º16çš„å€æ•°
                if (QString(accelNames[i]) == "qsv")
                {
                    testContext->width = 640;
                    testContext->height = 480;
                }
                
                int ret = avcodec_open2(testContext, codec, nullptr);
                if (ret >= 0)
                {
                    LOG_INFO("âœ“ Hardware encoder {} is available and working", codecName);
                    hwAccels << accelNames[i];
                    avcodec_free_context(&testContext);
                }
                else
                {
                    char errbuf[AV_ERROR_MAX_STRING_SIZE];
                    av_strerror(ret, errbuf, sizeof(errbuf));
                    LOG_DEBUG("âœ— Hardware encoder {} found but cannot be opened: {}", codecName, errbuf);
                    avcodec_free_context(&testContext);
                }
            }
        }
        else
        {
            LOG_DEBUG("Hardware encoder not found: {}", codecName);
        }
    }

    return hwAccels;
}

bool H264Encoder::initialize(int width, int height, int fps, int bitrate)
{
    QMutexLocker locker(&m_mutex);

    if (m_initialized)
    {
        LOG_INFO("Encoder already initialized, cleaning up first");
        cleanup();
    }

    m_width = width;
    m_height = height;
    m_fps = fps;
    m_bitrate = bitrate;

    // ä¼˜å…ˆå°è¯•ç¡¬ä»¶åŠ é€Ÿ
    QStringList hwAccels = getAvailableHWAccels();

    bool success = false;
    if (!hwAccels.isEmpty())
    {
        for (const QString &hwAccel : hwAccels)
        {
            LOG_INFO("Trying hardware acceleration: {}", hwAccel);
            if (initializeCodec(hwAccel))
            {
                LOG_INFO("Successfully initialized H264 encoder with {} acceleration", hwAccel);
                success = true;
                break;
            }
        }
    }

    // å¦‚æœç¡¬ä»¶åŠ é€Ÿå¤±è´¥ï¼Œä½¿ç”¨è½¯ä»¶ç¼–ç 
    if (!success)
    {
        LOG_INFO("Hardware acceleration not available, using software encoding");
        success = initializeCodec();
    }

    if (success)
    {
        m_initialized = true;
        QString accelType = m_hwAccelName.isEmpty() ? "software" : m_hwAccelName;
        LOG_INFO("ğŸ¯ H264 encoder successfully initialized with {} acceleration", accelType);

        // æ€§èƒ½ä¼˜åŒ–æç¤º
        if (m_hwAccelName.isEmpty())
        {
            LOG_INFO("ğŸ’¡ Using optimized software encoding - consider upgrading GPU drivers for hardware acceleration");
        }
        else
        {
            LOG_INFO("ğŸš€ Hardware acceleration active - optimal performance enabled");
        }
    }
    else
    {
        LOG_ERROR("âŒ Failed to initialize H264 encoder with any method");
        cleanup();
    }

    return success;
}

bool H264Encoder::initializeCodec(const QString &hwAccel)
{
    // æŸ¥æ‰¾ç¼–ç å™¨
    QString codecName = hwAccel.isEmpty() ? "libx264" : QString("h264_%1").arg(hwAccel);
    m_codec = avcodec_find_encoder_by_name(codecName.toUtf8().data());

    if (!m_codec)
    {
        LOG_ERROR("Codec {} not found", codecName);
        return false;
    }

    LOG_INFO("Found codec: {}", codecName);

    // åˆ›å»ºç¼–ç å™¨ä¸Šä¸‹æ–‡
    m_codecContext = avcodec_alloc_context3(m_codec);
    if (!m_codecContext)
    {
        LOG_ERROR("Could not allocate video codec context");
        return false;
    }

    // è®¾ç½®ç¼–ç å‚æ•°
    m_codecContext->bit_rate = m_bitrate;
    m_codecContext->width = m_width;
    m_codecContext->height = m_height;
    m_codecContext->time_base = AVRational{1, m_fps};
    m_codecContext->framerate = AVRational{m_fps, 1};
    m_codecContext->gop_size = m_fps;     // æ¯1ç§’ä¸€ä¸ªå…³é”®å¸§ï¼ˆæ›´é¢‘ç¹ï¼Œé¿å…èŠ±å±ï¼‰
    m_codecContext->max_b_frames = 0;     // ä¸ä½¿ç”¨Bå¸§ï¼Œåªä½¿ç”¨Iå¸§å’ŒPå¸§
    m_codecContext->keyint_min = m_fps / 2; // æœ€å°å…³é”®å¸§é—´éš”0.5ç§’

    // ç½‘ç»œè‡ªé€‚åº”ä¼˜åŒ–ï¼šé’ˆå¯¹é«˜å»¶è¿Ÿç½‘ç»œçš„ç¼–ç å‚æ•°
    m_codecContext->flags |= AV_CODEC_FLAG_LOW_DELAY;
    m_codecContext->flags2 |= AV_CODEC_FLAG2_FAST;
    m_codecContext->slices = 4;

    // è®¾ç½®ç¼–ç é¢„è®¾å’Œè°ƒä¼˜
    if (hwAccel.isEmpty())
    {
        // è½¯ä»¶ç¼–ç ä¼˜åŒ– - ç»Ÿä¸€ä½¿ç”¨NV12æ ¼å¼
        m_codecContext->pix_fmt = AV_PIX_FMT_NV12;
        m_hwPixelFormat = AV_PIX_FMT_NONE;
        m_hwDeviceCtx = nullptr;

        // éªŒè¯åˆ†è¾¨ç‡å‚æ•° - ç¡®ä¿åˆ†è¾¨ç‡æ˜¯å¶æ•°ï¼ˆH264è¦æ±‚ï¼‰
        if (m_width % 2 != 0 || m_height % 2 != 0)
        {
            LOG_WARN("Adjusting resolution from {}x{} to make it even for H264 compatibility", m_width, m_height);
            m_width = (m_width + 1) & ~1;
            m_height = (m_height + 1) & ~1;
            m_codecContext->width = m_width;
            m_codecContext->height = m_height;
        }

        // éªŒè¯æ¯”ç‰¹ç‡æ˜¯å¦åˆç†
        int minBitrate = m_width * m_height * m_fps * 0.05;
        int maxBitrate = m_width * m_height * m_fps * 0.5;
        if (m_bitrate < minBitrate)
        {
            m_bitrate = minBitrate;
            m_codecContext->bit_rate = m_bitrate;
            LOG_WARN("Adjusted bitrate to minimum safe value: {}", m_bitrate);
        }
        else if (m_bitrate > maxBitrate)
        {
            m_bitrate = maxBitrate;
            m_codecContext->bit_rate = m_bitrate;
            LOG_WARN("Adjusted bitrate to maximum safe value: {}", m_bitrate);
        }

        LOG_INFO("Setting software encoding parameters: {}x{}, {}fps, {}bps", m_width, m_height, m_fps, m_bitrate);
        
        // åŸºç¡€ç¼–ç é€‰é¡¹
        av_opt_set(m_codecContext->priv_data, "preset", "fast", 0);
        av_opt_set(m_codecContext->priv_data, "tune", "zerolatency", 0);
        av_opt_set(m_codecContext->priv_data, "profile", "baseline", 0); // ä½¿ç”¨baseline profileæé«˜å…¼å®¹æ€§
        
        // æ„å»ºå®Œæ•´çš„x264å‚æ•°å­—ç¬¦ä¸²ï¼Œç¡®ä¿Annex-Bæ ¼å¼å’Œé‡å¤SPS/PPS
        QString x264Params = QString("keyint=%1:min-keyint=%2:no-scenecut:repeat-headers=1:bframes=0:b-adapt=0")
                            .arg(m_fps)
                            .arg(m_fps / 2);
        av_opt_set(m_codecContext->priv_data, "x264-params", x264Params.toStdString().c_str(), 0);
        
        LOG_INFO("Software encoder configured with baseline profile, Annex-B format and repeat headers (GOP: {} frames)", m_fps);
    }
    else
    {
        // ç¡¬ä»¶åŠ é€Ÿåˆå§‹åŒ–
        LOG_INFO("Setting hardware encoding parameters: {}x{}, {}fps, {}bps", m_width, m_height, m_fps, m_bitrate);
        if (!initializeHardwareAccel(hwAccel))
        {
            return false;
        }
    }

    // æ‰“å¼€ç¼–ç å™¨
    int ret = avcodec_open2(m_codecContext, m_codec, nullptr);
    if (ret < 0)
    {
        char errbuf[AV_ERROR_MAX_STRING_SIZE];
        av_strerror(ret, errbuf, sizeof(errbuf));
        LOG_ERROR("Could not open codec {} ({}x{}, {}fps, {}bps): {} (error code: {})",
                  codecName, m_width, m_height, m_fps, m_bitrate, errbuf, ret);

        // å¦‚æœæ˜¯è½¯ä»¶ç¼–ç å™¨ï¼Œå°è¯•ä½¿ç”¨æ›´ä¿å®ˆçš„å‚æ•°
        if (hwAccel.isEmpty() && ret == AVERROR(EINVAL))
        {
            LOG_WARN("Trying with more conservative software encoding parameters");

            // é‡ç½®ç¼–ç å™¨ä¸Šä¸‹æ–‡
            avcodec_free_context(&m_codecContext);
            m_codecContext = avcodec_alloc_context3(m_codec);
            if (!m_codecContext)
            {
                LOG_ERROR("Could not allocate video codec context for retry");
                return false;
            }

            // ä½¿ç”¨æ›´ä¿å®ˆçš„å‚æ•°
            m_codecContext->bit_rate = m_width * m_height * m_fps * 0.1;
            m_codecContext->width = m_width;
            m_codecContext->height = m_height;
            m_codecContext->time_base = AVRational{1, m_fps};
            m_codecContext->framerate = AVRational{m_fps, 1};
            m_codecContext->gop_size = m_fps * 3; // æ¯3ç§’ä¸€ä¸ªå…³é”®å¸§
            m_codecContext->max_b_frames = 0;
            m_codecContext->keyint_min = m_fps;
            m_codecContext->pix_fmt = AV_PIX_FMT_NV12;

            av_opt_set(m_codecContext->priv_data, "preset", "ultrafast", 0);
            av_opt_set(m_codecContext->priv_data, "profile", "baseline", 0);

            ret = avcodec_open2(m_codecContext, m_codec, nullptr);
            if (ret < 0)
            {
                av_strerror(ret, errbuf, sizeof(errbuf));
                LOG_ERROR("Failed even with conservative parameters: {}", errbuf);
                return false;
            }
            else
            {
                LOG_INFO("Successfully opened codec with conservative parameters");
            }
        }
        else
        {
            return false;
        }
    }

    // åˆå§‹åŒ– Annex-B è¾“å‡ºé€‚é…ï¼ˆå¿…é¡»ï¼šä¸‹æ¸¸ WebRTC æ‰“åŒ…å™¨å’Œ decoder éƒ½åœ¨æŒ‰èµ·å§‹ç è§£æï¼‰
    if (!initAnnexBBsf())
    {
        LOG_WARN("Failed to initialize H264 bitstream filter (h264_mp4toannexb). Will output raw packets as-is.");
    }

    // åˆ†é…å¸§
    m_frame = av_frame_alloc();
    if (!m_frame)
    {
        LOG_ERROR("Could not allocate video frame");
        return false;
    }

    // æ‰€æœ‰ç¼–ç å™¨éƒ½ç»Ÿä¸€åˆ†é…bufferï¼ŒåŒ…æ‹¬QSV
    m_frame->format = m_codecContext->pix_fmt;
    m_frame->width = m_codecContext->width;
    m_frame->height = m_codecContext->height;

    ret = av_frame_get_buffer(m_frame, 32);
    if (ret < 0)
    {
        LOG_ERROR("Could not allocate video frame data");
        return false;
    }

    // åˆ†é…æ•°æ®åŒ…
    m_packet = av_packet_alloc();
    if (!m_packet)
    {
        LOG_ERROR("Could not allocate packet");
        return false;
    }

    // åˆå§‹åŒ–å›¾åƒæ ¼å¼è½¬æ¢å™¨ - ç»Ÿä¸€ä½¿ç”¨NV12æ ¼å¼ï¼Œæ‰€æœ‰ç¼–ç å™¨éƒ½æ”¯æŒ
    // æ³¨æ„ï¼šè¿™é‡Œæš‚ä¸åˆ›å»ºSwsContextï¼Œåœ¨qimageToAVFrameä¸­åŠ¨æ€åˆ›å»º
    // å› ä¸ºåˆ†è¾¨ç‡å¯èƒ½è¢«å¯¹é½ï¼Œéœ€è¦åœ¨è½¬æ¢æ—¶ç¡®å®šæ­£ç¡®çš„å‚æ•°

    m_hwAccelName = hwAccel;
    return true;
}

bool H264Encoder::initAnnexBBsf()
{
    // é‡Šæ”¾æ—§çš„ï¼ˆæ¯”å¦‚é‡å¤ initializeï¼‰
    if (m_h264Bsf)
    {
        av_bsf_free(&m_h264Bsf);
        m_h264Bsf = nullptr;
    }

    const AVBitStreamFilter *bsf = av_bsf_get_by_name("h264_mp4toannexb");
    if (!bsf)
    {
        LOG_WARN("Bitstream filter not found: h264_mp4toannexb");
        return false;
    }

    int ret = av_bsf_alloc(bsf, &m_h264Bsf);
    if (ret < 0 || !m_h264Bsf)
    {
        char errbuf[AV_ERROR_MAX_STRING_SIZE];
        av_strerror(ret, errbuf, sizeof(errbuf));
        LOG_WARN("av_bsf_alloc failed: {}", errbuf);
        m_h264Bsf = nullptr;
        return false;
    }

    if (!m_codecContext)
    {
        LOG_WARN("Codec context not ready for BSF init");
        av_bsf_free(&m_h264Bsf);
        m_h264Bsf = nullptr;
        return false;
    }

    // æŠŠç¼–ç å™¨å‚æ•°ä¼ ç»™ BSFï¼ˆSPS/PPS/extradata ç­‰ï¼‰
    ret = avcodec_parameters_from_context(m_h264Bsf->par_in, m_codecContext);
    if (ret < 0)
    {
        char errbuf[AV_ERROR_MAX_STRING_SIZE];
        av_strerror(ret, errbuf, sizeof(errbuf));
        LOG_WARN("avcodec_parameters_from_context failed: {}", errbuf);
        av_bsf_free(&m_h264Bsf);
        m_h264Bsf = nullptr;
        return false;
    }

    m_h264Bsf->time_base_in = m_codecContext->time_base;

    ret = av_bsf_init(m_h264Bsf);
    if (ret < 0)
    {
        char errbuf[AV_ERROR_MAX_STRING_SIZE];
        av_strerror(ret, errbuf, sizeof(errbuf));
        LOG_WARN("av_bsf_init failed: {}", errbuf);
        av_bsf_free(&m_h264Bsf);
        m_h264Bsf = nullptr;
        return false;
    }

    LOG_INFO("H264 bitstream filter initialized: h264_mp4toannexb (force Annex-B output)");
    return true;
}

rtc::binary H264Encoder::getAnnexBExtradata() const
{
    rtc::binary out;

    if (!m_codecContext || !m_codecContext->extradata || m_codecContext->extradata_size <= 0)
    {
        return out;
    }

    // é¦–é€‰ï¼šç”¨ h264_mp4toannexb æŠŠ AVCC extradata è½¬æˆ Annex-Bï¼ˆè‹¥ extradata æœ¬èº«å·²æ˜¯ Annex-B ä¹Ÿèƒ½æ­£å¸¸è¿”å›ï¼‰
    const AVBitStreamFilter *bsf = av_bsf_get_by_name("h264_mp4toannexb");
    if (!bsf)
    {
        return out;
    }

    AVBSFContext *ctx = nullptr;
    int ret = av_bsf_alloc(bsf, &ctx);
    if (ret < 0 || !ctx)
    {
        return out;
    }

    // æ‹·è´ codec å‚æ•°ï¼ˆè®© bsf çŸ¥é“ extradata çš„è§£ææ–¹å¼ï¼‰
    ret = avcodec_parameters_from_context(ctx->par_in, m_codecContext);
    if (ret < 0)
    {
        av_bsf_free(&ctx);
        return out;
    }

    // å¼ºåˆ¶æŠŠ extradata è¾“å…¥ç»™ bsfï¼ˆå†…éƒ¨ä¼šè½¬æˆ Annex-B é£æ ¼çš„ SPS/PPSï¼‰
    if (ctx->par_in->extradata && ctx->par_in->extradata_size > 0)
    {
        ctx->par_in->extradata = (uint8_t *)av_mallocz(m_codecContext->extradata_size + AV_INPUT_BUFFER_PADDING_SIZE);
        if (!ctx->par_in->extradata)
        {
            av_bsf_free(&ctx);
            return out;
        }
        memcpy(ctx->par_in->extradata, m_codecContext->extradata, m_codecContext->extradata_size);
        ctx->par_in->extradata_size = m_codecContext->extradata_size;
    }

    ctx->time_base_in = m_codecContext->time_base;

    ret = av_bsf_init(ctx);
    if (ret < 0)
    {
        av_bsf_free(&ctx);
        return out;
    }

    // è®© bsf äº§å‡ºå¸¦èµ·å§‹ç çš„ SPS/PPSï¼šåšæ³•æ˜¯é€ä¸€ä¸ªç©º packet è§¦å‘è¾“å‡º
    AVPacket *in = av_packet_alloc();
    if (!in)
    {
        av_bsf_free(&ctx);
        return out;
    }

    in->data = nullptr;
    in->size = 0;

    // æŸäº›ç‰ˆæœ¬è¦æ±‚å…ˆ send_packet/å† receive_packetï¼›å³ä½¿ EAGAIN/EOF ä¹Ÿæ— æ‰€è°“
    (void)av_bsf_send_packet(ctx, in);
    av_packet_free(&in);

    for (;;)
    {
        AVPacket *p = av_packet_alloc();
        if (!p)
        {
            break;
        }

        ret = av_bsf_receive_packet(ctx, p);
        if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF)
        {
            av_packet_free(&p);
            break;
        }
        if (ret < 0)
        {
            av_packet_free(&p);
            break;
        }

        size_t oldSize = out.size();
        out.resize(oldSize + static_cast<size_t>(p->size));
        memcpy(out.data() + oldSize, p->data, static_cast<size_t>(p->size));
        av_packet_free(&p);
    }

    av_bsf_free(&ctx);
    return out;
}

bool H264Encoder::annexBContainsSpsPps(const rtc::binary &annexb)
{
    if (annexb.size() < 5)
    {
        return false;
    }

    bool hasSps = false;
    bool hasPps = false;

    auto isStartCode4 = [&](size_t i) -> bool {
        return i + 3 < annexb.size() &&
               static_cast<uint8_t>(annexb[i]) == 0x00 &&
               static_cast<uint8_t>(annexb[i + 1]) == 0x00 &&
               static_cast<uint8_t>(annexb[i + 2]) == 0x00 &&
               static_cast<uint8_t>(annexb[i + 3]) == 0x01;
    };
    auto isStartCode3 = [&](size_t i) -> bool {
        return i + 2 < annexb.size() &&
               static_cast<uint8_t>(annexb[i]) == 0x00 &&
               static_cast<uint8_t>(annexb[i + 1]) == 0x00 &&
               static_cast<uint8_t>(annexb[i + 2]) == 0x01;
    };

    for (size_t i = 0; i + 4 < annexb.size(); ++i)
    {
        size_t nalOffset = 0;
        if (isStartCode4(i))
        {
            nalOffset = i + 4;
        }
        else if (isStartCode3(i))
        {
            nalOffset = i + 3;
        }
        else
        {
            continue;
        }

        if (nalOffset >= annexb.size())
        {
            continue;
        }

        uint8_t nalType = static_cast<uint8_t>(annexb[nalOffset]) & 0x1F;
        if (nalType == 7)
        {
            hasSps = true;
        }
        else if (nalType == 8)
        {
            hasPps = true;
        }

        if (hasSps && hasPps)
        {
            return true;
        }
    }

    return false;
}

rtc::binary H264Encoder::packetToAnnexBBinary(const AVPacket *packet)
{
    // å…œåº•ï¼šæ²¡æœ‰ BSF æˆ– packet ä¸ºç©ºï¼Œåˆ™åŸæ ·è¾“å‡º
    if (!packet || packet->size <= 0)
    {
        return rtc::binary();
    }

    if (!m_h264Bsf)
    {
        return avpacketToBinary(const_cast<AVPacket *>(packet));
    }

    // av_bsf_send_packet ä¼šæ¥ç®¡å¼•ç”¨è®¡æ•°ï¼šè¿™é‡Œç”¨ ref packet é¿å…å½±å“è°ƒç”¨æ–¹ packet ç”Ÿå‘½å‘¨æœŸ
    AVPacket *in = av_packet_alloc();
    if (!in)
    {
        return avpacketToBinary(const_cast<AVPacket *>(packet));
    }

    int ret = av_packet_ref(in, packet);
    if (ret < 0)
    {
        av_packet_free(&in);
        return avpacketToBinary(const_cast<AVPacket *>(packet));
    }

    ret = av_bsf_send_packet(m_h264Bsf, in);
    // send_packet æˆåŠŸå BSF ä¼šæŒæœ‰/é‡Šæ”¾ inï¼›å¤±è´¥åˆ™æˆ‘ä»¬é‡Šæ”¾
    if (ret < 0)
    {
        char errbuf[AV_ERROR_MAX_STRING_SIZE];
        av_strerror(ret, errbuf, sizeof(errbuf));
        LOG_WARN("av_bsf_send_packet failed: {}", errbuf);
        av_packet_free(&in);
        return avpacketToBinary(const_cast<AVPacket *>(packet));
    }

    rtc::binary result;

    for (;;)
    {
        AVPacket *out = av_packet_alloc();
        if (!out)
        {
            break;
        }

        ret = av_bsf_receive_packet(m_h264Bsf, out);
        if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF)
        {
            av_packet_free(&out);
            break;
        }
        if (ret < 0)
        {
            char errbuf[AV_ERROR_MAX_STRING_SIZE];
            av_strerror(ret, errbuf, sizeof(errbuf));
            LOG_WARN("av_bsf_receive_packet failed: {}", errbuf);
            av_packet_free(&out);
            break;
        }

        rtc::binary one = avpacketToBinary(out);
        result.insert(result.end(), one.begin(), one.end());
        av_packet_free(&out);
    }

    // å…œåº•ï¼šå…³é”®å¸§å¦‚æœæ²¡å¸¦ SPS/PPSï¼Œå°±æŠŠ extradata çš„ SPS/PPS å‰ç½®ï¼Œæå‡éšæœºèŠ±å±æ¢å¤èƒ½åŠ›ã€‚
    // æ³¨ï¼šåªåœ¨ packet è‡ªèº«è¢«æ ‡è®°ä¸ºå…³é”®å¸§æ—¶åšï¼ˆé¿å…æ¯å¸§éƒ½å¡å¤´ï¼Œå¸¦å®½æŠ–åŠ¨ï¼‰ã€‚
    if ((packet->flags & AV_PKT_FLAG_KEY) != 0)
    {
        if (!annexBContainsSpsPps(result))
        {
            rtc::binary extra = getAnnexBExtradata();
            if (!extra.empty())
            {
                // ç¡®ä¿ extra é‡Œä¹Ÿæœ‰èµ·å§‹ç ï¼›è‹¥ bsf æœªäº§å‡ºï¼Œåˆ™ä¸å‰ç½®
                if (extra.size() >= 4)
                {
                    rtc::binary merged;
                    merged.reserve(extra.size() + result.size());
                    merged.insert(merged.end(), extra.begin(), extra.end());
                    merged.insert(merged.end(), result.begin(), result.end());
                    result.swap(merged);
                    LOG_DEBUG("Prepended SPS/PPS extradata to keyframe packet (size: {} + {})", extra.size(), result.size());
                }
            }
        }
    }

    return result;
}
void H264Encoder::forceKeyFrame()
{
    QMutexLocker locker(&m_mutex);
    m_forceKeyFrame = true;
    LOG_INFO("ğŸ”‘ Force key frame requested");
}
rtc::binary H264Encoder::encodeFrame(const QImage &image)
{
    QMutexLocker locker(&m_mutex);

    if (!m_initialized)
    {
        LOG_ERROR("Encoder not initialized");
        return rtc::binary();
    }

    // ç¡®ä¿å›¾åƒæ ¼å¼ä¸ºRGB888
    QImage rgbImage = image;
    if (rgbImage.format() != QImage::Format_RGB888)
    {
        rgbImage = rgbImage.convertToFormat(QImage::Format_RGB888);
    }

    // ä¸åœ¨è¿™é‡Œè¿›è¡ŒQImageç¼©æ”¾ï¼Œè®©FFmpegçš„SwsContextå¤„ç†ç¼©æ”¾ä»¥è·å¾—æ›´å¥½çš„è´¨é‡
    // è½¬æ¢ä¸ºAVFrameï¼ˆFFmpegä¼šè‡ªåŠ¨å¤„ç†åˆ†è¾¨ç‡è½¬æ¢ï¼‰
    AVFrame *inputFrame = qimageToAVFrame(rgbImage);
    if (!inputFrame)
    {
        LOG_ERROR("Failed to convert QImage to AVFrame with scaling");
        return rtc::binary();
    }

    AVFrame *encodingFrame = inputFrame;

    // å¦‚æœä½¿ç”¨ç¡¬ä»¶åŠ é€Ÿï¼Œéœ€è¦å°†è½¯ä»¶å¸§ä¼ è¾“åˆ°ç¡¬ä»¶
    if (m_hwPixelFormat != AV_PIX_FMT_NONE && m_hwDeviceCtx)
    {
        AVFrame *hw = transferToHardware(inputFrame);
        av_frame_free(&inputFrame);
        encodingFrame = hw;
        if (!encodingFrame)
        {
            LOG_ERROR("Failed to transfer frame to hardware");
            return rtc::binary();
        }
    }

    // å¼ºåˆ¶ç¬¬ä¸€å¸§ä¸ºå…³é”®å¸§ï¼Œå¹¶ç¡®ä¿åŒ…å«SPS/PPSå‚æ•°é›†
    // åŒæ—¶æ¯éš”ä¸€å®šå¸§æ•°ï¼ˆGOPå¤§å°ï¼‰å¼ºåˆ¶ç”Ÿæˆå…³é”®å¸§ï¼Œé˜²æ­¢é•¿æ—¶é—´æ— å…³é”®å¸§å¯¼è‡´èŠ±å±
    bool needKeyFrame = (m_frameCount == 0 || m_forceKeyFrame || (m_frameCount % (m_fps * 2) == 0));
    
    if (needKeyFrame)
    {
        encodingFrame->pict_type = AV_PICTURE_TYPE_I;

        // æ³¨æ„ï¼šéƒ¨åˆ† FFmpeg ç‰ˆæœ¬çš„ AVFrame æ²¡æœ‰ key_frame å­—æ®µï¼ˆä¾‹å¦‚ 4.4 ç³»åˆ—å¤´æ–‡ä»¶ï¼‰ã€‚
        // è¿™é‡Œç”¨ flags åšå…¼å®¹æ ‡è®°ï¼›çœŸæ­£å¼ºåˆ¶ IDR ä¸»è¦ä¾èµ– pict_type + ç¼–ç å™¨ä¾§å‚æ•°/è¯·æ±‚ã€‚
#ifdef AV_FRAME_FLAG_KEY
        encodingFrame->flags |= AV_FRAME_FLAG_KEY;
#endif

        // å¯¹äºlibx264ï¼Œå¼ºåˆ¶ç«‹å³è¾“å‡ºå…³é”®å¸§
        if (m_hwAccelName.isEmpty()) {
            encodingFrame->pict_type = AV_PICTURE_TYPE_I;
        }

        if (m_frameCount % (m_fps * 2) == 0 && m_frameCount > 0)
        {
            LOG_DEBUG("ğŸ”‘ Auto-generating IDR frame at frame {} (every 2 seconds for robustness)", m_frameCount);
        }
        else
        {
            LOG_INFO("ğŸ”‘ Forcing IDR frame (frame count: {}, force key: {})", m_frameCount, m_forceKeyFrame);
        }
        m_forceKeyFrame = false; // é‡ç½®å¼ºåˆ¶å…³é”®å¸§æ ‡å¿—
    }

    // ç¼–ç å¸§
    int ret = avcodec_send_frame(m_codecContext, encodingFrame);

    // å¢åŠ å¸§è®¡æ•°
    m_frameCount++;

    // åªé‡Šæ”¾æˆ‘ä»¬å½“å‰æŒæœ‰çš„ encodingFrameï¼Œé¿å… inputFrame å†æ¬¡é‡Šæ”¾å¯¼è‡´å´©æºƒ
    av_frame_free(&encodingFrame);

    if (ret < 0)
    {
        char errbuf[AV_ERROR_MAX_STRING_SIZE];
        av_strerror(ret, errbuf, sizeof(errbuf));
        LOG_ERROR("Error sending frame to encoder: {}", errbuf);
        return rtc::binary();
    }

    rtc::binary result;

    // æ¥æ”¶ç¼–ç åçš„æ•°æ®åŒ…
    while (ret >= 0)
    {
        ret = avcodec_receive_packet(m_codecContext, m_packet);
        if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF)
        {
            break;
        }
        else if (ret < 0)
        {
            char errbuf[AV_ERROR_MAX_STRING_SIZE];
            av_strerror(ret, errbuf, sizeof(errbuf));
            LOG_ERROR("Error receiving packet from encoder: {}", errbuf);
            break;
        }

        if (m_packet->size > 0)
        {
            // å…³é”®ï¼šç»Ÿä¸€è½¬ Annex-Bï¼Œæœ€å¤§å…¼å®¹æ€§ï¼ˆWebRTC packetizer / è‡ªå®¶ decoder éƒ½æŒ‰èµ·å§‹ç è§£æï¼‰
            rtc::binary packetData = packetToAnnexBBinary(m_packet);
            if (!packetData.empty())
            {
                result.insert(result.end(), packetData.begin(), packetData.end());
            }
        }
        else
        {
            LOG_WARN("Received empty packet from encoder");
        }

        av_packet_unref(m_packet);
    }

    if (result.empty())
    {
        LOG_DEBUG("No encoded data produced (encoder buffering)");
    }

    return result;
}

AVFrame *H264Encoder::qimageToAVFrame(const QImage &image)
{
    AVFrame *frame = av_frame_alloc();
    if (!frame)
    {
        LOG_ERROR("Failed to allocate AVFrame");
        return nullptr;
    }

    // ç»Ÿä¸€ä½¿ç”¨NV12æ ¼å¼ï¼Œæ‰€æœ‰ç¼–ç å™¨éƒ½æ”¯æŒ
    AVPixelFormat targetFormat = AV_PIX_FMT_NV12;

    frame->format = targetFormat;
    frame->width = m_width;
    frame->height = m_height;

    // ç¡®ä¿å¸§æ—¶é—´åŸºå‡†è®¾ç½®æ­£ç¡®
    frame->pts = AV_NOPTS_VALUE;

    // ä¸ºå¸§åˆ†é…ç¼“å†²åŒºï¼Œä½¿ç”¨32å­—èŠ‚å¯¹é½
    int ret = av_frame_get_buffer(frame, 32);
    if (ret < 0)
    {
        char errbuf[AV_ERROR_MAX_STRING_SIZE];
        av_strerror(ret, errbuf, sizeof(errbuf));
        LOG_ERROR("Could not allocate video frame data: {}", errbuf);
        av_frame_free(&frame);
        return nullptr;
    }

    // RGBæ•°æ®æŒ‡é’ˆ
    const uint8_t *srcData[1] = {image.constBits()};
    int srcLinesize[1] = {static_cast<int>(image.bytesPerLine())};

    // æ£€æŸ¥SwsContextæ˜¯å¦æœ‰æ•ˆï¼Œæˆ–è€…éœ€è¦é‡æ–°åˆ›å»º
    AVPixelFormat currentTargetFormat = AV_PIX_FMT_NV12;

    // è·å–è¾“å…¥å›¾åƒçš„å®é™…å°ºå¯¸
    int inputWidth = image.width();
    int inputHeight = image.height();

    // æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°åˆ›å»ºSwsContextï¼ˆè¾“å…¥å°ºå¯¸æ”¹å˜æˆ–é¦–æ¬¡åˆ›å»ºï¼‰
    static int lastInputWidth = -1;
    static int lastInputHeight = -1;

    if (!m_swsContext || inputWidth != lastInputWidth || inputHeight != lastInputHeight)
    {
        // é‡æ–°åˆ›å»ºSwsContextä»¥é€‚åº”æ–°çš„è¾“å…¥å°ºå¯¸
        if (m_swsContext)
        {
            sws_freeContext(m_swsContext);
        }

        m_swsContext = sws_getContext(
            inputWidth, inputHeight, AV_PIX_FMT_RGB24, // è¾“å…¥ï¼šå®é™…å›¾åƒå°ºå¯¸
            m_width, m_height, currentTargetFormat,    // è¾“å‡ºï¼šç¼–ç å™¨å°ºå¯¸
            SWS_BILINEAR, nullptr, nullptr, nullptr    // ä½¿ç”¨åŒçº¿æ€§æ’å€¼è·å¾—æ›´å¥½è´¨é‡
        );

        if (!m_swsContext)
        {
            LOG_ERROR("SwsContext creation failed for RGB24 to NV12 conversion ({}x{} -> {}x{})",
                      inputWidth, inputHeight, m_width, m_height);
            av_frame_free(&frame);
            return nullptr;
        }

        lastInputWidth = inputWidth;
        lastInputHeight = inputHeight;

        LOG_DEBUG("Created SwsContext for RGB24 to NV12 conversion with scaling: {}x{} -> {}x{}",
                  inputWidth, inputHeight, m_width, m_height);
    }

    // è½¬æ¢RGBåˆ°NV12æ ¼å¼ï¼ˆåŒæ—¶è¿›è¡Œç¼©æ”¾ï¼‰
    int swsRet = sws_scale(m_swsContext,
                           srcData, srcLinesize, 0, inputHeight, // ä½¿ç”¨è¾“å…¥å›¾åƒçš„é«˜åº¦
                           frame->data, frame->linesize);

    if (swsRet != m_height)
    { // è¾“å‡ºåº”è¯¥æ˜¯ç¼–ç å™¨çš„é«˜åº¦
        LOG_ERROR("sws_scale failed: expected {} lines, got {}", m_height, swsRet);
        av_frame_free(&frame);
        return nullptr;
    }

    return frame;
}

rtc::binary H264Encoder::avpacketToBinary(AVPacket *packet)
{
    rtc::binary data;
    data.resize(packet->size);

    for (int i = 0; i < packet->size; ++i)
    {
        data[i] = static_cast<std::byte>(packet->data[i]);
    }

    // è¯¦ç»†è°ƒè¯•ï¼šæ£€æŸ¥è¾“å‡ºæ•°æ®çš„NALå•å…ƒç±»å‹
    if (data.size() >= 5)
    {
        // æŸ¥æ‰¾æ‰€æœ‰NALå•å…ƒ
        int nalCount = 0;
        for (size_t i = 0; i + 4 < data.size(); ++i)
        {
            if (static_cast<uint8_t>(data[i]) == 0x00 &&
                static_cast<uint8_t>(data[i+1]) == 0x00 &&
                static_cast<uint8_t>(data[i+2]) == 0x00 &&
                static_cast<uint8_t>(data[i+3]) == 0x01)
            {
                uint8_t nalType = static_cast<uint8_t>(data[i+4]) & 0x1F;
                const char* nalTypeName = "Unknown";
                switch(nalType) {
                    case 1: nalTypeName = "Non-IDR"; break;
                    case 5: nalTypeName = "IDR"; break;
                    case 6: nalTypeName = "SEI"; break;
                    case 7: nalTypeName = "SPS"; break;
                    case 8: nalTypeName = "PPS"; break;
                    case 9: nalTypeName = "AUD"; break;
                }
                
                if (nalCount == 0) {
                    LOG_DEBUG("H264 packet: size={}, NAL units found:", packet->size);
                }
                LOG_DEBUG("  NAL[{}] at offset {}: type={} ({})", nalCount, i, nalType, nalTypeName);
                nalCount++;
                
                i += 4; // è·³è¿‡èµ·å§‹ç 
            }
        }
        
        if (nalCount == 0) {
            LOG_WARN("âš ï¸ No Annex-B start codes found in packet! First 4 bytes: {:02x} {:02x} {:02x} {:02x}",
                     static_cast<uint8_t>(data[0]), static_cast<uint8_t>(data[1]),
                     static_cast<uint8_t>(data[2]), static_cast<uint8_t>(data[3]));
        }
    }

    return data;
}

AVFrame *H264Encoder::transferToHardware(AVFrame *swFrame)
{
    if (!m_hwDeviceCtx || m_hwPixelFormat == AV_PIX_FMT_NONE)
    {
        // ä¸éœ€è¦ç¡¬ä»¶ä¼ è¾“ï¼Œç›´æ¥è¿”å›åŸå¸§
        return av_frame_clone(swFrame);
    }

    // æ£€æŸ¥ç¡¬ä»¶å¸§ä¸Šä¸‹æ–‡æ˜¯å¦æœ‰æ•ˆ
    if (!m_codecContext || !m_codecContext->hw_frames_ctx)
    {
        LOG_WARN("Hardware frames context not available, falling back to software frame");
        return av_frame_clone(swFrame);
    }

    // åˆ›å»ºç¡¬ä»¶å¸§
    AVFrame *hwFrame = av_frame_alloc();
    if (!hwFrame)
    {
        LOG_ERROR("Failed to allocate hardware frame");
        return nullptr;
    }

    // ä¸ºç¡¬ä»¶å¸§åˆ†é…ç¼“å†²åŒº - å¿…é¡»å…ˆåˆ†é…æ‰èƒ½è®¾ç½®å±æ€§
    int ret = av_hwframe_get_buffer(m_codecContext->hw_frames_ctx, hwFrame, 0);
    if (ret < 0)
    {
        char errbuf[AV_ERROR_MAX_STRING_SIZE];
        av_strerror(ret, errbuf, sizeof(errbuf));
        LOG_ERROR("Failed to allocate hardware frame buffer: {}", errbuf);
        av_frame_free(&hwFrame);
        return nullptr;
    }

    // è®¾ç½®ç¡¬ä»¶å¸§å±æ€§ï¼ˆåœ¨åˆ†é…ç¼“å†²åŒºåï¼‰
    hwFrame->width = m_codecContext->width;
    hwFrame->height = m_codecContext->height;

    // å¦‚æœè½¯ä»¶å¸§å°ºå¯¸ä¸ç¡¬ä»¶å¸§å°ºå¯¸ä¸åŒï¼Œéœ€è¦å…ˆç¼©æ”¾
    AVFrame *scaledFrame = swFrame;
    if (swFrame->width != hwFrame->width || swFrame->height != hwFrame->height)
    {
        scaledFrame = av_frame_alloc();
        if (!scaledFrame)
        {
            LOG_ERROR("Failed to allocate scaled frame");
            av_frame_free(&hwFrame);
            return nullptr;
        }

        scaledFrame->format = swFrame->format;
        scaledFrame->width = hwFrame->width;
        scaledFrame->height = hwFrame->height;

        ret = av_frame_get_buffer(scaledFrame, 32);
        if (ret < 0)
        {
            LOG_ERROR("Failed to allocate scaled frame buffer");
            av_frame_free(&hwFrame);
            av_frame_free(&scaledFrame);
            return nullptr;
        }

        // åˆ›å»ºä¸´æ—¶çš„swsä¸Šä¸‹æ–‡è¿›è¡Œç¼©æ”¾
        struct SwsContext *tempSwsCtx = sws_getContext(
            swFrame->width, swFrame->height, static_cast<AVPixelFormat>(swFrame->format),
            scaledFrame->width, scaledFrame->height, static_cast<AVPixelFormat>(scaledFrame->format),
            SWS_BILINEAR, nullptr, nullptr, nullptr);

        if (!tempSwsCtx)
        {
            LOG_ERROR("Failed to create temporary sws context for scaling");
            av_frame_free(&hwFrame);
            av_frame_free(&scaledFrame);
            return nullptr;
        }

        sws_scale(tempSwsCtx,
                  swFrame->data, swFrame->linesize, 0, swFrame->height,
                  scaledFrame->data, scaledFrame->linesize);

        sws_freeContext(tempSwsCtx);
    }

    // ä¼ è¾“æ•°æ®åˆ°ç¡¬ä»¶å¸§
    ret = av_hwframe_transfer_data(hwFrame, scaledFrame, 0);
    if (ret < 0)
    {
        char errbuf[AV_ERROR_MAX_STRING_SIZE];
        av_strerror(ret, errbuf, sizeof(errbuf));
        LOG_ERROR("Failed to transfer data to hardware frame: {}", errbuf);
        av_frame_free(&hwFrame);
        if (scaledFrame != swFrame)
        {
            av_frame_free(&scaledFrame);
        }
        return nullptr;
    }

    // æ¸…ç†ä¸´æ—¶å¸§
    if (scaledFrame != swFrame)
    {
        av_frame_free(&scaledFrame);
    }

    return hwFrame;
}

bool H264Encoder::initializeHardwareAccel(const QString &hwAccel)
{
    if (!m_codecContext)
    {
        LOG_ERROR("initializeHardwareAccel called with null codec context");
        return false;
    }

    // QSV å•ç‹¬èµ°ï¼ˆå®ƒå¯¹ hw_frames_ctx/å¯¹é½æ›´æ•æ„Ÿï¼‰
    if (hwAccel == "qsv")
    {
        return initializeQSV();
    }

    // å…³é”®ä¿®æ­£ï¼šNVENC/AMF/MF/D3D12VA è¿™ç±»ç¼–ç å™¨ç»å¤§å¤šæ•°æœŸæœ›çš„æ˜¯ system-memory NV12 è¾“å…¥ï¼Œ
    // ä¸éœ€è¦ä¹Ÿä¸åº”è¯¥é…ç½® hw_frames_ctxï¼Œæ›´ä¸è¦æŠŠ pix_fmt è®¾æˆ CUDA/VAAPI ç­‰ç¡¬ä»¶åƒç´ æ ¼å¼ã€‚
    // å¦åˆ™ avcodec_send_frame() å¾ˆå®¹æ˜“æŠ¥ "Generic error in an external library"ã€‚

    // å…ˆé»˜è®¤èµ°â€œè½¯ä»¶å¸§è¾“å…¥â€ï¼ˆNV12ï¼‰
    m_hwPixelFormat = AV_PIX_FMT_NONE;
    m_codecContext->pix_fmt = AV_PIX_FMT_NV12;

    // åˆ†è¾¨ç‡å¯¹é½ï¼šä¿å®ˆå¤„ç†ï¼Œé¿å…ç¡¬ç¼–åƒä¸ä¸‹ï¼ˆå°¤å…¶æ˜¯ NVENC/D3D12VA å¯¹å¥‡æ•°åˆ†è¾¨ç‡å¾ˆæ•æ„Ÿï¼‰
    if ((m_codecContext->width & 1) || (m_codecContext->height & 1))
    {
        int w = (m_codecContext->width + 1) & ~1;
        int h = (m_codecContext->height + 1) & ~1;
        LOG_WARN("Aligning HW encoder resolution from {}x{} to {}x{}", m_codecContext->width, m_codecContext->height, w, h);
        m_codecContext->width = w;
        m_codecContext->height = h;
        m_width = w;
        m_height = h;
    }

    // ä»…å¯¹æ˜ç¡®éœ€è¦ hwframe çš„ç¼–ç å™¨æ‰å»åˆ›å»º/ç»‘å®š hwdevice + hwframesã€‚
    // Windows å¸¸è§ï¼š
    // - h264_nvenc / h264_mf / h264_d3d12va : NV12 system-memory
    // - h264_vaapi / h264_videotoolbox     : é€šå¸¸éœ€è¦ hw pix_fmt
    bool needHwFrames = false;

    if (hwAccel == "vaapi")
    {
        needHwFrames = true;
        m_hwPixelFormat = AV_PIX_FMT_VAAPI;
        m_codecContext->pix_fmt = m_hwPixelFormat;
    }
    else if (hwAccel == "videotoolbox")
    {
        needHwFrames = true;
        m_hwPixelFormat = AV_PIX_FMT_VIDEOTOOLBOX;
        m_codecContext->pix_fmt = m_hwPixelFormat;
    }
    else if (hwAccel == "cuda")
    {
        // h264_cuda å¾ˆå°‘è§ä¸”è¡Œä¸ºä¸ nvenc ä¸åŒï¼›è‹¥ç”¨æˆ·çœŸè¦èµ°å®ƒï¼Œåˆ™æŒ‰ hwframe è·¯å¾„å¤„ç†ã€‚
        needHwFrames = true;
        m_hwPixelFormat = AV_PIX_FMT_CUDA;
        m_codecContext->pix_fmt = m_hwPixelFormat;
    }

    if (needHwFrames)
    {
        m_hwDeviceCtx = HardwareContextManager::instance().getDeviceContext(hwAccel);
        if (!m_hwDeviceCtx)
        {
            LOG_ERROR("Failed to create/get hardware device context for {}", hwAccel);
            m_hwPixelFormat = AV_PIX_FMT_NONE;
            m_codecContext->pix_fmt = AV_PIX_FMT_NV12;
            return false;
        }

        m_codecContext->hw_device_ctx = av_buffer_ref(m_hwDeviceCtx);
        if (!m_codecContext->hw_device_ctx)
        {
            LOG_ERROR("Failed to ref hw_device_ctx for {}", hwAccel);
            return false;
        }

        AVBufferRef *hwFramesRef = av_hwframe_ctx_alloc(m_hwDeviceCtx);
        if (!hwFramesRef)
        {
            LOG_ERROR("Failed to allocate hwframe context for {}", hwAccel);
            return false;
        }

        AVHWFramesContext *framesCtx = reinterpret_cast<AVHWFramesContext *>(hwFramesRef->data);
        framesCtx->format = m_hwPixelFormat;
        framesCtx->sw_format = AV_PIX_FMT_NV12;
        framesCtx->width = m_codecContext->width;
        framesCtx->height = m_codecContext->height;
        framesCtx->initial_pool_size = 20;

        int ret = av_hwframe_ctx_init(hwFramesRef);
        if (ret < 0)
        {
            char errbuf[AV_ERROR_MAX_STRING_SIZE];
            av_strerror(ret, errbuf, sizeof(errbuf));
            LOG_ERROR("Failed to init hwframe context for {}: {}", hwAccel, errbuf);
            av_buffer_unref(&hwFramesRef);
            return false;
        }

        m_codecContext->hw_frames_ctx = hwFramesRef;
    }

    // ç¡¬ç¼–ä¸“æœ‰å‚æ•°ï¼ˆç¨³å®šä¼˜å…ˆã€ä½å»¶è¿Ÿï¼‰
    if (hwAccel == "nvenc")
    {
        // è¯´æ˜ï¼šä¸åŒ FFmpeg/NVENC ç‰ˆæœ¬å¯ç”¨å€¼ä¸åŒï¼›è¿™é‡Œé€‰æ‹©ç›¸å¯¹ä¿å®ˆä¸”å¹¿æ³›æ”¯æŒçš„å–å€¼
        av_opt_set(m_codecContext->priv_data, "preset", "p4", 0);
        av_opt_set(m_codecContext->priv_data, "tune", "ll", 0);
        av_opt_set(m_codecContext->priv_data, "rc", "cbr", 0);
        av_opt_set(m_codecContext->priv_data, "forced-idr", "1", 0);
        av_opt_set(m_codecContext->priv_data, "repeat-headers", "1", 0);

        // æ˜ç¡® profileï¼Œé¿å…æŸäº›é©±åŠ¨/æ„å»ºé»˜è®¤é«˜ profile å¯¼è‡´å…¼å®¹æ€§é—®é¢˜
        av_opt_set(m_codecContext->priv_data, "profile", "baseline", 0);

        // è‹¥é©±åŠ¨æ”¯æŒï¼Œå¯ç”¨ 0-latencyï¼ˆä¸æ”¯æŒä¼šè¢«å¿½ç•¥/è¿”å›é”™è¯¯ï¼ŒFFmpeg ä¸ä¼šå› æ­¤å´©ï¼‰
        av_opt_set(m_codecContext->priv_data, "zerolatency", "1", 0);
    }
    else if (hwAccel == "amf")
    {
        av_opt_set(m_codecContext->priv_data, "usage", "lowlatency", 0);
        av_opt_set(m_codecContext->priv_data, "rc", "cbr", 0);
        av_opt_set(m_codecContext->priv_data, "repeat-headers", "1", 0);
        av_opt_set(m_codecContext->priv_data, "profile", "baseline", 0);
    }
    else if (hwAccel == "mf")
    {
        // MF é€šå¸¸åƒ NV12 system-memory
        m_codecContext->pix_fmt = AV_PIX_FMT_NV12;

        // æœ‰äº› build æ”¯æŒä¸‹åˆ—é€‰é¡¹ï¼Œæœ‰äº›ä¸æ”¯æŒï¼›ä¸æ”¯æŒçš„è¯ opt_set å¤±è´¥ä¹Ÿä¸è‡´å‘½
        av_opt_set(m_codecContext->priv_data, "rate_control", "cbr", 0);
    }
    else if (hwAccel == "d3d12va")
    {
        // d3d12va ç¼–ç å™¨åŒæ ·é€šå¸¸åƒ NV12 system-memory
        m_codecContext->pix_fmt = AV_PIX_FMT_NV12;
    }
    else if (hwAccel == "vaapi")
    {
        av_opt_set(m_codecContext->priv_data, "rc_mode", "CBR", 0);
        av_opt_set(m_codecContext->priv_data, "low_power", "1", 0);
        av_opt_set(m_codecContext->priv_data, "idr_interval", "1", 0);
    }

    m_codecContext->max_b_frames = 0;

    LOG_INFO("Hardware encoder pre-configured: hwAccel={}, pix_fmt={}, hwPixFmt={}, hwFramesCtx={}",
             hwAccel,
             av_get_pix_fmt_name(m_codecContext->pix_fmt),
             (m_hwPixelFormat == AV_PIX_FMT_NONE ? "none" : av_get_pix_fmt_name(m_hwPixelFormat)),
             (m_codecContext->hw_frames_ctx ? "yes" : "no"));

    return true;
}

bool H264Encoder::initializeQSV()
{
    if (!m_codecContext)
    {
        return false;
    }

    // QSV å¯¹åˆ†è¾¨ç‡å¯¹é½å¾ˆæ•æ„Ÿï¼šæŒ‰ 16 å¯¹é½
    int alignedW = (m_codecContext->width + 15) & ~15;
    int alignedH = (m_codecContext->height + 15) & ~15;
    if (alignedW != m_codecContext->width || alignedH != m_codecContext->height)
    {
        LOG_WARN("Aligning QSV resolution from {}x{} to {}x{}", m_codecContext->width, m_codecContext->height, alignedW, alignedH);
        m_codecContext->width = alignedW;
        m_codecContext->height = alignedH;
        m_width = alignedW;
        m_height = alignedH;
    }

    // QSVï¼šä¼˜å…ˆèµ° NV12 system-memory è¾“å…¥ï¼ˆæ›´å…¼å®¹ï¼Œé¿å…å¤æ‚çš„ hwframe ç®¡çº¿ï¼‰
    m_codecContext->pix_fmt = AV_PIX_FMT_NV12;
    m_hwPixelFormat = AV_PIX_FMT_NONE;

    // QSV å¸¸ç”¨ç¨³å®šå‚æ•°ï¼ˆä¸ä¸€å®šæ¯ä¸ª build éƒ½æ”¯æŒï¼Œè®¾ç½®å¤±è´¥ä¸ä¼šè‡´å‘½ï¼‰
    av_opt_set(m_codecContext->priv_data, "async_depth", "1", 0);
    av_opt_set(m_codecContext->priv_data, "look_ahead", "0", 0);
    av_opt_set(m_codecContext->priv_data, "b", "0", 0);
    av_opt_set(m_codecContext->priv_data, "bf", "0", 0);
    av_opt_set(m_codecContext->priv_data, "repeat-headers", "1", 0);

    LOG_INFO("QSV encoder pre-configured: pix_fmt=NV12, aligned {}x{}", m_codecContext->width, m_codecContext->height);
    return true;
}

void H264Encoder::cleanup()
{
    if (m_packet)
    {
        av_packet_free(&m_packet);
        m_packet = nullptr;
    }

    if (m_frame)
    {
        av_frame_free(&m_frame);
        m_frame = nullptr;
    }

    if (m_hwFrame)
    {
        av_frame_free(&m_hwFrame);
        m_hwFrame = nullptr;
    }

    if (m_swsContext)
    {
        sws_freeContext(m_swsContext);
        m_swsContext = nullptr;
    }

    if (m_codecContext)
    {
        avcodec_free_context(&m_codecContext);
        m_codecContext = nullptr;
    }

    // é‡Šæ”¾ç¡¬ä»¶è®¾å¤‡ä¸Šä¸‹æ–‡çš„å¼•ç”¨ï¼ˆå…±äº«ç®¡ç†å™¨ä¼šå¤„ç†å®é™…çš„é‡Šæ”¾ï¼‰
    if (m_hwDeviceCtx)
    {
        av_buffer_unref(&m_hwDeviceCtx);
        m_hwDeviceCtx = nullptr;
    }

    // é‡Šæ”¾ BSF
    if (m_h264Bsf)
    {
        av_bsf_free(&m_h264Bsf);
        m_h264Bsf = nullptr;
    }

    m_codec = nullptr;
    m_hwPixelFormat = AV_PIX_FMT_NONE;
    m_hwAccelName.clear();
    m_initialized = false;

    LOG_DEBUG("H264Encoder cleanup completed");
}
