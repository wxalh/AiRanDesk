#include "h264_encoder.h"
#include "logger_manager.h"
#include <QDebug>
#include <cstdio>

// ç¡¬ä»¶è®¾å¤‡ä¸Šä¸‹æ–‡ç®¡ç†å™¨ - å•ä¾‹æ¨¡å¼ï¼Œé¿å…é‡å¤åˆ›å»ºç¡¬ä»¶ä¸Šä¸‹æ–‡
class HardwareContextManager
{
public:
    static HardwareContextManager &instance()
    {
        static HardwareContextManager instance;
        return instance;
    }

    AVBufferRef *getDeviceContext(const QString &hwAccel)
    {
        QMutexLocker locker(&m_mutex);

        if (m_contexts.contains(hwAccel))
        {
            AVBufferRef *ctx = m_contexts[hwAccel];
            if (ctx)
            {
                return av_buffer_ref(ctx);
            }
            else
            {
                m_contexts.remove(hwAccel);
            }
        }

        AVHWDeviceType deviceType = av_hwdevice_find_type_by_name(hwAccel.toUtf8().data());
        if (deviceType == AV_HWDEVICE_TYPE_NONE)
        {
            LOG_ERROR("Hardware device type not found: {}", hwAccel);
            return nullptr;
        }

        AVBufferRef *newCtx = nullptr;
        int ret = av_hwdevice_ctx_create(&newCtx, deviceType, nullptr, nullptr, 0);
        if (ret < 0)
        {
            if (hwAccel == "qsv")
            {
                ret = av_hwdevice_ctx_create(&newCtx, deviceType, "auto", nullptr, 0);
            }

            if (ret < 0)
            {
                char errbuf[AV_ERROR_MAX_STRING_SIZE];
                av_strerror(ret, errbuf, sizeof(errbuf));
                LOG_WARN("Failed to create shared hardware device context {}: {}", hwAccel, errbuf);
                return nullptr;
            }
        }

        m_contexts[hwAccel] = newCtx;
        LOG_DEBUG("Created shared hardware device context for: {}", hwAccel);
        return av_buffer_ref(newCtx);
    }

private:
    QMap<QString, AVBufferRef *> m_contexts;
    QMutex m_mutex;
};

H264Encoder::H264Encoder(QObject *parent)
    : QObject(parent), m_codecContext(nullptr), m_codec(nullptr), m_frame(nullptr)
    , m_hwFrame(nullptr), m_packet(nullptr), m_swsContext(nullptr), m_hwDeviceCtx(nullptr)
    , m_width(0), m_height(0), m_fps(30), m_bitrate(2000000), m_frameCount(0)
    , m_hwPixelFormat(AV_PIX_FMT_NONE), m_initialized(false), m_forceKeyFrame(false)
{
}

H264Encoder::~H264Encoder()
{
    cleanup();
}

QStringList H264Encoder::getAvailableHWAccels()
{
    QStringList hwAccels;

    // æ£€æŸ¥å¸¸è§çš„ç¡¬ä»¶åŠ é€Ÿå™¨ï¼ŒæŒ‰ä¼˜å…ˆçº§æ’åº
    const char *accelNames[] = {
        "qsv",          // Intel Quick Sync (ä¼˜å…ˆæ£€æµ‹)
        "nvenc",        // NVIDIA
        "amf",          // AMD
        "videotoolbox", // macOS
        "v4l2m2m",      // Linux V4L2
        "omx",          // OpenMAX
        "rkmpp",       // Rockchip MPP
        "mpp",         // MPP
        "mppenc",     // MPP Encoder
        nullptr};

    for (int i = 0; accelNames[i]; ++i)
    {
        QString codecName = QString("h264_%1").arg(accelNames[i]);
        const AVCodec *codec = avcodec_find_encoder_by_name(codecName.toUtf8().data());
        if (codec)
        {
            LOG_INFO("Found hardware encoder: {}", codecName);
            hwAccels << accelNames[i];
        }
        else
        {
            LOG_DEBUG("Hardware encoder not found: {}", codecName);
        }
    }

    return hwAccels;
}

bool H264Encoder::initialize(int width, int height, int fps, int bitrate)
{
    QMutexLocker locker(&m_mutex);

    if (m_initialized)
    {
        LOG_INFO("Encoder already initialized, cleaning up first");
        cleanup();
    }

    m_width = width;
    m_height = height;
    m_fps = fps;
    m_bitrate = bitrate;

    // ä¼˜å…ˆå°è¯•ç¡¬ä»¶åŠ é€Ÿ
    QStringList hwAccels = getAvailableHWAccels();

    bool success = false;
    if (!hwAccels.isEmpty())
    {
        for (const QString &hwAccel : hwAccels)
        {
            LOG_INFO("Trying hardware acceleration: {}", hwAccel);
            if (initializeCodec(hwAccel))
            {
                LOG_INFO("Successfully initialized H264 encoder with {} acceleration", hwAccel);
                success = true;
                break;
            }
        }
    }

    // å¦‚æœç¡¬ä»¶åŠ é€Ÿå¤±è´¥ï¼Œä½¿ç”¨è½¯ä»¶ç¼–ç 
    if (!success)
    {
        LOG_INFO("Hardware acceleration not available, using software encoding");
        success = initializeCodec();
    }

    if (success)
    {
        m_initialized = true;
        QString accelType = m_hwAccelName.isEmpty() ? "software" : m_hwAccelName;
        LOG_INFO("ğŸ¯ H264 encoder successfully initialized with {} acceleration", accelType);

        // æ€§èƒ½ä¼˜åŒ–æç¤º
        if (m_hwAccelName.isEmpty())
        {
            LOG_INFO("ğŸ’¡ Using optimized software encoding - consider upgrading GPU drivers for hardware acceleration");
        }
        else
        {
            LOG_INFO("ğŸš€ Hardware acceleration active - optimal performance enabled");
        }
    }
    else
    {
        LOG_ERROR("âŒ Failed to initialize H264 encoder with any method");
        cleanup();
    }

    return success;
}

bool H264Encoder::initializeCodec(const QString &hwAccel)
{
    // æŸ¥æ‰¾ç¼–ç å™¨
    QString codecName = hwAccel.isEmpty() ? "libx264" : QString("h264_%1").arg(hwAccel);
    m_codec = avcodec_find_encoder_by_name(codecName.toUtf8().data());

    if (!m_codec)
    {
        LOG_ERROR("Codec {} not found", codecName);
        return false;
    }

    LOG_INFO("Found codec: {}", codecName);

    // åˆ›å»ºç¼–ç å™¨ä¸Šä¸‹æ–‡
    m_codecContext = avcodec_alloc_context3(m_codec);
    if (!m_codecContext)
    {
        LOG_ERROR("Could not allocate video codec context");
        return false;
    }

    // è®¾ç½®ç¼–ç å‚æ•°
    m_codecContext->bit_rate = m_bitrate;
    m_codecContext->width = m_width;
    m_codecContext->height = m_height;
    m_codecContext->time_base = AVRational{1, m_fps};
    m_codecContext->framerate = AVRational{m_fps, 1};
    m_codecContext->gop_size = m_fps * 3; // æ¯3ç§’ä¸€ä¸ªå…³é”®å¸§
    m_codecContext->max_b_frames = 0;     // ä¸ä½¿ç”¨Bå¸§ï¼Œåªä½¿ç”¨Iå¸§å’ŒPå¸§
    m_codecContext->keyint_min = m_fps;   // æœ€å°å…³é”®å¸§é—´éš”1ç§’

    // ç½‘ç»œè‡ªé€‚åº”ä¼˜åŒ–ï¼šé’ˆå¯¹é«˜å»¶è¿Ÿç½‘ç»œçš„ç¼–ç å‚æ•°
    m_codecContext->flags |= AV_CODEC_FLAG_LOW_DELAY;
    m_codecContext->flags2 |= AV_CODEC_FLAG2_FAST;
    m_codecContext->slices = 4;

    // è®¾ç½®ç¼–ç é¢„è®¾å’Œè°ƒä¼˜
    if (hwAccel.isEmpty())
    {
        // è½¯ä»¶ç¼–ç ä¼˜åŒ– - ç»Ÿä¸€ä½¿ç”¨NV12æ ¼å¼
        m_codecContext->pix_fmt = AV_PIX_FMT_NV12;
        m_hwPixelFormat = AV_PIX_FMT_NONE;
        m_hwDeviceCtx = nullptr;

        // éªŒè¯åˆ†è¾¨ç‡å‚æ•° - ç¡®ä¿åˆ†è¾¨ç‡æ˜¯å¶æ•°ï¼ˆH264è¦æ±‚ï¼‰
        if (m_width % 2 != 0 || m_height % 2 != 0)
        {
            LOG_WARN("Adjusting resolution from {}x{} to make it even for H264 compatibility", m_width, m_height);
            m_width = (m_width + 1) & ~1;
            m_height = (m_height + 1) & ~1;
            m_codecContext->width = m_width;
            m_codecContext->height = m_height;
        }

        // éªŒè¯æ¯”ç‰¹ç‡æ˜¯å¦åˆç†
        int minBitrate = m_width * m_height * m_fps * 0.05;
        int maxBitrate = m_width * m_height * m_fps * 0.5;
        if (m_bitrate < minBitrate)
        {
            m_bitrate = minBitrate;
            m_codecContext->bit_rate = m_bitrate;
            LOG_WARN("Adjusted bitrate to minimum safe value: {}", m_bitrate);
        }
        else if (m_bitrate > maxBitrate)
        {
            m_bitrate = maxBitrate;
            m_codecContext->bit_rate = m_bitrate;
            LOG_WARN("Adjusted bitrate to maximum safe value: {}", m_bitrate);
        }

        LOG_INFO("Setting software encoding parameters: {}x{}, {}fps, {}bps", m_width, m_height, m_fps, m_bitrate);
        av_opt_set(m_codecContext->priv_data, "preset", "fast", 0);
        av_opt_set(m_codecContext->priv_data, "tune", "zerolatency", 0);
        av_opt_set(m_codecContext->priv_data, "x264opts", "no-mbtree:sliced-threads:rc-lookahead=10", 0);
        
        // ä½¿ç”¨Annex-Bæ ¼å¼ï¼ŒåŒ…å«èµ·å§‹ç ï¼Œä¾¿äºåç»­SPS/PPSæå–
        av_opt_set(m_codecContext->priv_data, "annex-b", "1", 0);
        // å…¼å®¹åç§°ï¼ˆéƒ¨åˆ†ç‰ˆæœ¬ä½¿ç”¨ annexbï¼‰
        av_opt_set(m_codecContext->priv_data, "annexb", "1", 0);
        // ç¡®ä¿æ¯ä¸ªIDRå‰é‡å¤è¾“å‡ºSPS/PPSï¼ˆlibx264ï¼‰
        av_opt_set(m_codecContext->priv_data, "x264-params", "nal-hrd=cbr:force-cfr=1:repeat-headers=1", 0);
        
        LOG_INFO("Software encoder configured for Annex-B and repeat headers on keyframes");
    }
    else
    {
        // ç¡¬ä»¶åŠ é€Ÿåˆå§‹åŒ–
        LOG_INFO("Setting hardware encoding parameters: {}x{}, {}fps, {}bps", m_width, m_height, m_fps, m_bitrate);
        if (!initializeHardwareAccel(hwAccel))
        {
            return false;
        }
    }

    // æ‰“å¼€ç¼–ç å™¨
    int ret = avcodec_open2(m_codecContext, m_codec, nullptr);
    if (ret < 0)
    {
        char errbuf[AV_ERROR_MAX_STRING_SIZE];
        av_strerror(ret, errbuf, sizeof(errbuf));
        LOG_ERROR("Could not open codec {} ({}x{}, {}fps, {}bps): {} (error code: {})",
                  codecName, m_width, m_height, m_fps, m_bitrate, errbuf, ret);

        // å¦‚æœæ˜¯è½¯ä»¶ç¼–ç å™¨ï¼Œå°è¯•ä½¿ç”¨æ›´ä¿å®ˆçš„å‚æ•°
        if (hwAccel.isEmpty() && ret == AVERROR(EINVAL))
        {
            LOG_WARN("Trying with more conservative software encoding parameters");

            // é‡ç½®ç¼–ç å™¨ä¸Šä¸‹æ–‡
            avcodec_free_context(&m_codecContext);
            m_codecContext = avcodec_alloc_context3(m_codec);
            if (!m_codecContext)
            {
                LOG_ERROR("Could not allocate video codec context for retry");
                return false;
            }

            // ä½¿ç”¨æ›´ä¿å®ˆçš„å‚æ•°
            m_codecContext->bit_rate = m_width * m_height * m_fps * 0.1;
            m_codecContext->width = m_width;
            m_codecContext->height = m_height;
            m_codecContext->time_base = AVRational{1, m_fps};
            m_codecContext->framerate = AVRational{m_fps, 1};
            m_codecContext->gop_size = m_fps * 3; // æ¯3ç§’ä¸€ä¸ªå…³é”®å¸§
            m_codecContext->max_b_frames = 0;
            m_codecContext->keyint_min = m_fps;
            m_codecContext->pix_fmt = AV_PIX_FMT_NV12;

            av_opt_set(m_codecContext->priv_data, "preset", "ultrafast", 0);
            av_opt_set(m_codecContext->priv_data, "profile", "baseline", 0);

            ret = avcodec_open2(m_codecContext, m_codec, nullptr);
            if (ret < 0)
            {
                av_strerror(ret, errbuf, sizeof(errbuf));
                LOG_ERROR("Failed even with conservative parameters: {}", errbuf);
                return false;
            }
            else
            {
                LOG_INFO("Successfully opened codec with conservative parameters");
            }
        }
        else
        {
            return false;
        }
    }

    // åˆ†é…å¸§
    m_frame = av_frame_alloc();
    if (!m_frame)
    {
        LOG_ERROR("Could not allocate video frame");
        return false;
    }

    // æ‰€æœ‰ç¼–ç å™¨éƒ½ç»Ÿä¸€åˆ†é…bufferï¼ŒåŒ…æ‹¬QSV
    m_frame->format = m_codecContext->pix_fmt;
    m_frame->width = m_codecContext->width;
    m_frame->height = m_codecContext->height;

    ret = av_frame_get_buffer(m_frame, 32);
    if (ret < 0)
    {
        LOG_ERROR("Could not allocate video frame data");
        return false;
    }

    // åˆ†é…æ•°æ®åŒ…
    m_packet = av_packet_alloc();
    if (!m_packet)
    {
        LOG_ERROR("Could not allocate packet");
        return false;
    }

    // åˆå§‹åŒ–å›¾åƒæ ¼å¼è½¬æ¢å™¨ - ç»Ÿä¸€ä½¿ç”¨NV12æ ¼å¼ï¼Œæ‰€æœ‰ç¼–ç å™¨éƒ½æ”¯æŒ
    // æ³¨æ„ï¼šè¿™é‡Œæš‚ä¸åˆ›å»ºSwsContextï¼Œåœ¨qimageToAVFrameä¸­åŠ¨æ€åˆ›å»º
    // å› ä¸ºåˆ†è¾¨ç‡å¯èƒ½è¢«å¯¹é½ï¼Œéœ€è¦åœ¨è½¬æ¢æ—¶ç¡®å®šæ­£ç¡®çš„å‚æ•°

    m_hwAccelName = hwAccel;
    return true;
}

bool H264Encoder::initializeHardwareAccel(const QString &hwAccel)
{
    if (hwAccel == "qsv")
    {
        // QSVç‰¹æ®Šå¤„ç†ï¼šä½¿ç”¨ç®€åŒ–åˆå§‹åŒ–
        return initializeQSV();
    }

    // å…¶ä»–ç¡¬ä»¶åŠ é€Ÿå™¨çš„é€šç”¨å¤„ç†
    if (hwAccel == "nvenc")
    {
        // NVENCç»Ÿä¸€ä½¿ç”¨NV12æ ¼å¼
        m_codecContext->pix_fmt = AV_PIX_FMT_NV12;
        m_hwPixelFormat = AV_PIX_FMT_NONE;

        // NVENCç‰¹å®šé€‰é¡¹
        av_opt_set(m_codecContext->priv_data, "preset", "fast", 0);
        av_opt_set(m_codecContext->priv_data, "profile", "high", 0);
        av_opt_set(m_codecContext->priv_data, "rc", "cbr", 0);
        // ç¡®ä¿å¼ºåˆ¶å…³é”®å¸§ä¸ºIDR
        av_opt_set(m_codecContext->priv_data, "forced-idr", "1", 0);
        // ç¡®ä¿æ¯ä¸ªIDRå‰é‡å¤è¾“å‡ºSPS/PPS
        av_opt_set(m_codecContext->priv_data, "repeat-headers", "1", 0);
        // ä½¿ç”¨Annex-Bèµ·å§‹ç 
        av_opt_set(m_codecContext->priv_data, "annexb", "1", 0);

        LOG_INFO("NVENC encoder configured with Annex-B, forced IDR and repeat headers on keyframes");
        return true;
    }
    else if (hwAccel == "amf")
    {
        // AMFç»Ÿä¸€ä½¿ç”¨NV12æ ¼å¼
        m_codecContext->pix_fmt = AV_PIX_FMT_NV12;
        m_hwPixelFormat = AV_PIX_FMT_NONE;

        // AMFç‰¹å®šé€‰é¡¹
        av_opt_set(m_codecContext->priv_data, "usage", "lowlatency", 0);
        av_opt_set(m_codecContext->priv_data, "profile", "high", 0);
        av_opt_set(m_codecContext->priv_data, "rc", "cbr", 0);
        // å°è¯•åœ¨å…³é”®å¸§é‡å¤SPS/PPSï¼ˆå–å†³äºé©±åŠ¨/ç‰ˆæœ¬æ”¯æŒï¼‰
        av_opt_set(m_codecContext->priv_data, "repeat-headers", "1", 0);
        // ä½¿ç”¨Annex-Bèµ·å§‹ç ï¼ˆè‹¥æ”¯æŒï¼‰
        av_opt_set(m_codecContext->priv_data, "annexb", "1", 0);

        LOG_INFO("AMF encoder configured with Annex-B and repeat headers on keyframes");
        return true;
    }
    else if (hwAccel == "videotoolbox")
    {
        m_hwPixelFormat = AV_PIX_FMT_VIDEOTOOLBOX;
        m_codecContext->pix_fmt = AV_PIX_FMT_VIDEOTOOLBOX;
    }
    else
    {
        m_codecContext->pix_fmt = AV_PIX_FMT_NV12;
        return true;
    }

    // åªæœ‰VideoToolboxéœ€è¦ç¡¬ä»¶è®¾å¤‡ä¸Šä¸‹æ–‡
    if (hwAccel == "videotoolbox")
    {
        // ä½¿ç”¨å…±äº«çš„ç¡¬ä»¶è®¾å¤‡ä¸Šä¸‹æ–‡ç®¡ç†å™¨
        m_hwDeviceCtx = HardwareContextManager::instance().getDeviceContext("videotoolbox");
        if (!m_hwDeviceCtx)
        {
            LOG_ERROR("Failed to get shared VideoToolbox device context");
            return false;
        }

        m_codecContext->hw_device_ctx = av_buffer_ref(m_hwDeviceCtx);

        // åˆ›å»ºç¡¬ä»¶å¸§ä¸Šä¸‹æ–‡
        AVBufferRef *hwFramesRef = av_hwframe_ctx_alloc(m_hwDeviceCtx);
        if (!hwFramesRef)
        {
            LOG_ERROR("Failed to allocate hardware frames context");
            return false;
        }

        AVHWFramesContext *hwFramesCtx = (AVHWFramesContext *)hwFramesRef->data;
        hwFramesCtx->format = m_hwPixelFormat;
        hwFramesCtx->sw_format = AV_PIX_FMT_NV12;
        hwFramesCtx->width = m_width;
        hwFramesCtx->height = m_height;
        hwFramesCtx->initial_pool_size = 20;

        int ret = av_hwframe_ctx_init(hwFramesRef);
        if (ret < 0)
        {
            char errbuf[AV_ERROR_MAX_STRING_SIZE];
            av_strerror(ret, errbuf, sizeof(errbuf));
            LOG_ERROR("Failed to initialize hardware frames context: {}", errbuf);
            av_buffer_unref(&hwFramesRef);
            return false;
        }

        m_codecContext->hw_frames_ctx = hwFramesRef;
    }

    return true;
}

bool H264Encoder::initializeQSV()
{
    LOG_INFO("Initializing Intel QSV encoder with NV12 software format for compatibility");

    // QSVè¦æ±‚åˆ†è¾¨ç‡å¿…é¡»æ˜¯16çš„å€æ•°ï¼Œè°ƒæ•´åˆ†è¾¨ç‡
    int alignedWidth = (m_width + 15) & ~15;
    int alignedHeight = (m_height + 15) & ~15;

    if (alignedWidth != m_width || alignedHeight != m_height)
    {
        LOG_INFO("Aligning QSV resolution from {}x{} to {}x{}", m_width, m_height, alignedWidth, alignedHeight);
        m_codecContext->width = alignedWidth;
        m_codecContext->height = alignedHeight;
    }

    // QSVç»Ÿä¸€ä½¿ç”¨NV12è½¯ä»¶æ ¼å¼ï¼Œé¿å…ç¡¬ä»¶å¸§ä¸Šä¸‹æ–‡é—®é¢˜
    m_codecContext->pix_fmt = AV_PIX_FMT_NV12;
    m_hwPixelFormat = AV_PIX_FMT_NONE;
    m_hwDeviceCtx = nullptr;

    // QSVç‰¹å®šçš„ç¼–ç å™¨é€‰é¡¹
    av_opt_set(m_codecContext->priv_data, "preset", "medium", 0);
    av_opt_set(m_codecContext->priv_data, "profile", "high", 0);

    // QSVç‰¹å®šå‚æ•°è°ƒæ•´
    m_codecContext->max_b_frames = 0;

    // ä¸ºæ¯ä¸ªå…³é”®å¸§é‡å¤SPS/PPSï¼ˆå¦‚æ”¯æŒï¼‰
    av_opt_set(m_codecContext->priv_data, "repeat-headers", "1", 0);

    LOG_INFO("QSV encoder configured with repeat headers on keyframes");
    return true;
}
void H264Encoder::forceKeyFrame()
{
    QMutexLocker locker(&m_mutex);
    m_forceKeyFrame = true;
    LOG_INFO("ğŸ”‘ Force key frame requested");
}
rtc::binary H264Encoder::encodeFrame(const QImage &image)
{
    QMutexLocker locker(&m_mutex);

    if (!m_initialized)
    {
        LOG_ERROR("Encoder not initialized");
        return rtc::binary();
    }

    // ç¡®ä¿å›¾åƒæ ¼å¼ä¸ºRGB888
    QImage rgbImage = image;
    if (rgbImage.format() != QImage::Format_RGB888)
    {
        rgbImage = rgbImage.convertToFormat(QImage::Format_RGB888);
    }

    // ä¸åœ¨è¿™é‡Œè¿›è¡ŒQImageç¼©æ”¾ï¼Œè®©FFmpegçš„SwsContextå¤„ç†ç¼©æ”¾ä»¥è·å¾—æ›´å¥½çš„è´¨é‡
    // è½¬æ¢ä¸ºAVFrameï¼ˆFFmpegä¼šè‡ªåŠ¨å¤„ç†åˆ†è¾¨ç‡è½¬æ¢ï¼‰
    AVFrame *inputFrame = qimageToAVFrame(rgbImage);
    if (!inputFrame)
    {
        LOG_ERROR("Failed to convert QImage to AVFrame with scaling");
        return rtc::binary();
    }

    AVFrame *encodingFrame = inputFrame;

    // å¦‚æœä½¿ç”¨ç¡¬ä»¶åŠ é€Ÿï¼Œéœ€è¦å°†è½¯ä»¶å¸§ä¼ è¾“åˆ°ç¡¬ä»¶
    if (m_hwPixelFormat != AV_PIX_FMT_NONE && m_hwDeviceCtx)
    {
        encodingFrame = transferToHardware(inputFrame);
        av_frame_free(&inputFrame);
        if (!encodingFrame)
        {
            LOG_ERROR("Failed to transfer frame to hardware");
            return rtc::binary();
        }
    }

    // å¼ºåˆ¶ç¬¬ä¸€å¸§ä¸ºå…³é”®å¸§ï¼Œå¹¶ç¡®ä¿åŒ…å«SPS/PPSå‚æ•°é›†
    if (m_frameCount == 0 || m_forceKeyFrame)
    {
        encodingFrame->pict_type = AV_PICTURE_TYPE_I;
        encodingFrame->key_frame = 1;
        
        LOG_INFO("ğŸ”‘ Forcing IDR frame (frame count: {}, force key: {})", m_frameCount, m_forceKeyFrame);
        m_forceKeyFrame = false; // é‡ç½®å¼ºåˆ¶å…³é”®å¸§æ ‡å¿—
    }

    // ç¼–ç å¸§
    int ret = avcodec_send_frame(m_codecContext, encodingFrame);

    // å¢åŠ å¸§è®¡æ•°
    m_frameCount++;

    av_frame_free(&encodingFrame);

    if (ret < 0)
    {
        char errbuf[AV_ERROR_MAX_STRING_SIZE];
        av_strerror(ret, errbuf, sizeof(errbuf));
        LOG_ERROR("Error sending frame to encoder: {}", errbuf);
        return rtc::binary();
    }

    rtc::binary result;

    // æ¥æ”¶ç¼–ç åçš„æ•°æ®åŒ…
    while (ret >= 0)
    {
        ret = avcodec_receive_packet(m_codecContext, m_packet);
        if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF)
        {
            break;
        }
        else if (ret < 0)
        {
            char errbuf[AV_ERROR_MAX_STRING_SIZE];
            av_strerror(ret, errbuf, sizeof(errbuf));
            LOG_ERROR("Error receiving packet from encoder: {}", errbuf);
            break;
        }

        // ç¡®ä¿æ•°æ®åŒ…ä¸ä¸ºç©º
        if (m_packet->size > 0)
        {
            // è½¬æ¢æ•°æ®åŒ…ä¸ºäºŒè¿›åˆ¶æ•°æ®
            rtc::binary packetData = avpacketToBinary(m_packet);
            result.insert(result.end(), packetData.begin(), packetData.end());
        }
        else
        {
            LOG_WARN("Received empty packet from encoder");
        }

        av_packet_unref(m_packet);
    }

    if (result.empty())
    {
        LOG_DEBUG("No encoded data produced (encoder buffering)");
    }

    return result;
}

AVFrame *H264Encoder::qimageToAVFrame(const QImage &image)
{
    AVFrame *frame = av_frame_alloc();
    if (!frame)
    {
        LOG_ERROR("Failed to allocate AVFrame");
        return nullptr;
    }

    // ç»Ÿä¸€ä½¿ç”¨NV12æ ¼å¼ï¼Œæ‰€æœ‰ç¼–ç å™¨éƒ½æ”¯æŒ
    AVPixelFormat targetFormat = AV_PIX_FMT_NV12;

    frame->format = targetFormat;
    frame->width = m_width;
    frame->height = m_height;

    // ç¡®ä¿å¸§æ—¶é—´åŸºå‡†è®¾ç½®æ­£ç¡®
    frame->pts = AV_NOPTS_VALUE;

    // ä¸ºå¸§åˆ†é…ç¼“å†²åŒºï¼Œä½¿ç”¨32å­—èŠ‚å¯¹é½
    int ret = av_frame_get_buffer(frame, 32);
    if (ret < 0)
    {
        char errbuf[AV_ERROR_MAX_STRING_SIZE];
        av_strerror(ret, errbuf, sizeof(errbuf));
        LOG_ERROR("Could not allocate video frame data: {}", errbuf);
        av_frame_free(&frame);
        return nullptr;
    }

    // RGBæ•°æ®æŒ‡é’ˆ
    const uint8_t *srcData[1] = {image.constBits()};
    int srcLinesize[1] = {static_cast<int>(image.bytesPerLine())};

    // æ£€æŸ¥SwsContextæ˜¯å¦æœ‰æ•ˆï¼Œæˆ–è€…éœ€è¦é‡æ–°åˆ›å»º
    AVPixelFormat currentTargetFormat = AV_PIX_FMT_NV12;

    // è·å–è¾“å…¥å›¾åƒçš„å®é™…å°ºå¯¸
    int inputWidth = image.width();
    int inputHeight = image.height();

    // æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°åˆ›å»ºSwsContextï¼ˆè¾“å…¥å°ºå¯¸æ”¹å˜æˆ–é¦–æ¬¡åˆ›å»ºï¼‰
    static int lastInputWidth = -1;
    static int lastInputHeight = -1;

    if (!m_swsContext || inputWidth != lastInputWidth || inputHeight != lastInputHeight)
    {
        // é‡æ–°åˆ›å»ºSwsContextä»¥é€‚åº”æ–°çš„è¾“å…¥å°ºå¯¸
        if (m_swsContext)
        {
            sws_freeContext(m_swsContext);
        }

        m_swsContext = sws_getContext(
            inputWidth, inputHeight, AV_PIX_FMT_RGB24, // è¾“å…¥ï¼šå®é™…å›¾åƒå°ºå¯¸
            m_width, m_height, currentTargetFormat,    // è¾“å‡ºï¼šç¼–ç å™¨å°ºå¯¸
            SWS_BILINEAR, nullptr, nullptr, nullptr    // ä½¿ç”¨åŒçº¿æ€§æ’å€¼è·å¾—æ›´å¥½è´¨é‡
        );

        if (!m_swsContext)
        {
            LOG_ERROR("SwsContext creation failed for RGB24 to NV12 conversion ({}x{} -> {}x{})",
                      inputWidth, inputHeight, m_width, m_height);
            av_frame_free(&frame);
            return nullptr;
        }

        lastInputWidth = inputWidth;
        lastInputHeight = inputHeight;

        LOG_DEBUG("Created SwsContext for RGB24 to NV12 conversion with scaling: {}x{} -> {}x{}",
                  inputWidth, inputHeight, m_width, m_height);
    }

    // è½¬æ¢RGBåˆ°NV12æ ¼å¼ï¼ˆåŒæ—¶è¿›è¡Œç¼©æ”¾ï¼‰
    int swsRet = sws_scale(m_swsContext,
                           srcData, srcLinesize, 0, inputHeight, // ä½¿ç”¨è¾“å…¥å›¾åƒçš„é«˜åº¦
                           frame->data, frame->linesize);

    if (swsRet != m_height)
    { // è¾“å‡ºåº”è¯¥æ˜¯ç¼–ç å™¨çš„é«˜åº¦
        LOG_ERROR("sws_scale failed: expected {} lines, got {}", m_height, swsRet);
        av_frame_free(&frame);
        return nullptr;
    }

    return frame;
}

rtc::binary H264Encoder::avpacketToBinary(AVPacket *packet)
{
    rtc::binary data;
    data.resize(packet->size);

    for (int i = 0; i < packet->size; ++i)
    {
        data[i] = static_cast<std::byte>(packet->data[i]);
    }

    // è°ƒè¯•ï¼šæ£€æŸ¥è¾“å‡ºæ•°æ®çš„èµ·å§‹ç 
    if (data.size() >= 4)
    {
        LOG_DEBUG("H264 packet: size={}, first 4 bytes: {:02x} {:02x} {:02x} {:02x}",
                  packet->size,
                  static_cast<uint8_t>(data[0]), static_cast<uint8_t>(data[1]),
                  static_cast<uint8_t>(data[2]), static_cast<uint8_t>(data[3]));
    }

    return data;
}

AVFrame *H264Encoder::transferToHardware(AVFrame *swFrame)
{
    if (!m_hwDeviceCtx || m_hwPixelFormat == AV_PIX_FMT_NONE)
    {
        // ä¸éœ€è¦ç¡¬ä»¶ä¼ è¾“ï¼Œç›´æ¥è¿”å›åŸå¸§
        return av_frame_clone(swFrame);
    }

    // æ£€æŸ¥ç¡¬ä»¶å¸§ä¸Šä¸‹æ–‡æ˜¯å¦æœ‰æ•ˆ
    if (!m_codecContext || !m_codecContext->hw_frames_ctx)
    {
        LOG_WARN("Hardware frames context not available, falling back to software frame");
        return av_frame_clone(swFrame);
    }

    // åˆ›å»ºç¡¬ä»¶å¸§
    AVFrame *hwFrame = av_frame_alloc();
    if (!hwFrame)
    {
        LOG_ERROR("Failed to allocate hardware frame");
        return nullptr;
    }

    // ä¸ºç¡¬ä»¶å¸§åˆ†é…ç¼“å†²åŒº - å¿…é¡»å…ˆåˆ†é…æ‰èƒ½è®¾ç½®å±æ€§
    int ret = av_hwframe_get_buffer(m_codecContext->hw_frames_ctx, hwFrame, 0);
    if (ret < 0)
    {
        char errbuf[AV_ERROR_MAX_STRING_SIZE];
        av_strerror(ret, errbuf, sizeof(errbuf));
        LOG_ERROR("Failed to allocate hardware frame buffer: {}", errbuf);
        av_frame_free(&hwFrame);
        return nullptr;
    }

    // è®¾ç½®ç¡¬ä»¶å¸§å±æ€§ï¼ˆåœ¨åˆ†é…ç¼“å†²åŒºåï¼‰
    hwFrame->width = m_codecContext->width;
    hwFrame->height = m_codecContext->height;

    // å¦‚æœè½¯ä»¶å¸§å°ºå¯¸ä¸ç¡¬ä»¶å¸§å°ºå¯¸ä¸åŒï¼Œéœ€è¦å…ˆç¼©æ”¾
    AVFrame *scaledFrame = swFrame;
    if (swFrame->width != hwFrame->width || swFrame->height != hwFrame->height)
    {
        scaledFrame = av_frame_alloc();
        if (!scaledFrame)
        {
            LOG_ERROR("Failed to allocate scaled frame");
            av_frame_free(&hwFrame);
            return nullptr;
        }

        scaledFrame->format = swFrame->format;
        scaledFrame->width = hwFrame->width;
        scaledFrame->height = hwFrame->height;

        ret = av_frame_get_buffer(scaledFrame, 32);
        if (ret < 0)
        {
            LOG_ERROR("Failed to allocate scaled frame buffer");
            av_frame_free(&hwFrame);
            av_frame_free(&scaledFrame);
            return nullptr;
        }

        // åˆ›å»ºä¸´æ—¶çš„swsä¸Šä¸‹æ–‡è¿›è¡Œç¼©æ”¾
        struct SwsContext *tempSwsCtx = sws_getContext(
            swFrame->width, swFrame->height, static_cast<AVPixelFormat>(swFrame->format),
            scaledFrame->width, scaledFrame->height, static_cast<AVPixelFormat>(scaledFrame->format),
            SWS_BILINEAR, nullptr, nullptr, nullptr);

        if (!tempSwsCtx)
        {
            LOG_ERROR("Failed to create temporary sws context for scaling");
            av_frame_free(&hwFrame);
            av_frame_free(&scaledFrame);
            return nullptr;
        }

        sws_scale(tempSwsCtx,
                  swFrame->data, swFrame->linesize, 0, swFrame->height,
                  scaledFrame->data, scaledFrame->linesize);

        sws_freeContext(tempSwsCtx);
    }

    // ä¼ è¾“æ•°æ®åˆ°ç¡¬ä»¶å¸§
    ret = av_hwframe_transfer_data(hwFrame, scaledFrame, 0);
    if (ret < 0)
    {
        char errbuf[AV_ERROR_MAX_STRING_SIZE];
        av_strerror(ret, errbuf, sizeof(errbuf));
        LOG_ERROR("Failed to transfer data to hardware frame: {}", errbuf);
        av_frame_free(&hwFrame);
        if (scaledFrame != swFrame)
        {
            av_frame_free(&scaledFrame);
        }
        return nullptr;
    }

    // æ¸…ç†ä¸´æ—¶å¸§
    if (scaledFrame != swFrame)
    {
        av_frame_free(&scaledFrame);
    }

    return hwFrame;
}

void H264Encoder::cleanup()
{
    if (m_packet)
    {
        av_packet_free(&m_packet);
        m_packet = nullptr;
    }

    if (m_frame)
    {
        av_frame_free(&m_frame);
        m_frame = nullptr;
    }

    if (m_hwFrame)
    {
        av_frame_free(&m_hwFrame);
        m_hwFrame = nullptr;
    }

    if (m_swsContext)
    {
        sws_freeContext(m_swsContext);
        m_swsContext = nullptr;
    }

    if (m_codecContext)
    {
        avcodec_free_context(&m_codecContext);
        m_codecContext = nullptr;
    }

    // é‡Šæ”¾ç¡¬ä»¶è®¾å¤‡ä¸Šä¸‹æ–‡çš„å¼•ç”¨ï¼ˆå…±äº«ç®¡ç†å™¨ä¼šå¤„ç†å®é™…çš„é‡Šæ”¾ï¼‰
    if (m_hwDeviceCtx)
    {
        av_buffer_unref(&m_hwDeviceCtx);
        m_hwDeviceCtx = nullptr;
    }

    m_codec = nullptr;
    m_hwPixelFormat = AV_PIX_FMT_NONE;
    m_hwAccelName.clear();
    m_initialized = false;

    LOG_DEBUG("H264Encoder cleanup completed");
}
